{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a59160a",
   "metadata": {},
   "source": [
    "# Final Project Notebook\n",
    "\n",
    "**University of California, Berkeley**\n",
    "\n",
    "**MIDS Program** - W207 Applied Machine Learning\n",
    "\n",
    "**Section 7** - Mackenzie Austin, Emanuel Mej√≠a, Ibrahim Shareef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ffa7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install imblearn\n",
    "# ! pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50898ae6-2e37-4824-9da5-dbd2bd3350d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#from PIL import Image\n",
    "import seaborn as sns  # for nicer plots\n",
    "sns.set(style=\"darkgrid\")  # default style\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "#import sklearn\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "#tf.get_logger().setLevel('INFO')\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "start = timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540274f2-4068-4e30-850a-1f94d2fdaac9",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">Download and Load Data </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42911dfb-5834-40b7-99dd-2f854f9d49ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#setup dataset\n",
    "\n",
    "# !mkdir input\n",
    "# !cd input && kaggle datasets download -d sachinkumar413/alzheimer-mri-dataset && tar -xf alzheimer-mri-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54668bcf-a4b6-41c7-814e-bf48d6f6c345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.empty((6400, 128, 128, 3))\n",
    "Y = np.empty(6400, dtype=int)\n",
    "label_names = ['Non Demented', 'Very Mild Demented', 'Mild Demented', 'Moderate Demented']\n",
    "index = 0\n",
    "for subdir, dirs, files in os.walk('./input/Dataset/Non_Demented'):\n",
    "    \n",
    "    for file in files:\n",
    "        img = load_img(os.path.join(subdir, file), target_size=(128,128))\n",
    "        #print(type(img))\n",
    "        #print(img.format)\n",
    "        #print(img.mode)\n",
    "        #print(img.size)\n",
    "        \n",
    "#         for grayscale\n",
    "#         img_arr = img_to_array(img.convert('L'))\n",
    "#         print(img_arr.shape)\n",
    "#         print(img_arr)\n",
    "#         img_arr = img_arr.reshape((128,-1))\n",
    "#         print(img_arr.shape)\n",
    "#         print(img_arr)\n",
    "        \n",
    "        img_arr = img_to_array(img)\n",
    "        X[index] = img_arr\n",
    "        Y[index] = 0\n",
    "        index += 1\n",
    "        \n",
    "for subdir, dirs, files in os.walk('./input/Dataset/Very_Mild_Demented'):\n",
    "    for file in files:\n",
    "        img = load_img(os.path.join(subdir, file), target_size=(128,128))\n",
    "        img_arr = img_to_array(img)\n",
    "        X[index] = img_arr\n",
    "        Y[index] = 1\n",
    "        index += 1\n",
    "        \n",
    "for subdir, dirs, files in os.walk('./input/Dataset/Mild_Demented'):\n",
    "    for file in files:\n",
    "        img = load_img(os.path.join(subdir, file), target_size=(128,128))\n",
    "        img_arr = img_to_array(img)\n",
    "        X[index] = img_arr\n",
    "        Y[index] = 2\n",
    "        index += 1\n",
    "        \n",
    "for subdir, dirs, files in os.walk('./input/Dataset/Moderate_Demented'):\n",
    "    for file in files:\n",
    "        img = load_img(os.path.join(subdir, file), target_size=(128,128))\n",
    "        img_arr = img_to_array(img)\n",
    "        X[index] = img_arr\n",
    "        Y[index] = 3\n",
    "        index += 1\n",
    "        \n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses = pd.Series(Y)\n",
    "diagnoses = diagnoses.replace([0, 1, 2, 3], label_names)\n",
    "diag_df = pd.DataFrame({'count': diagnoses.value_counts()})\n",
    "diag_df['%'] = round(diag_df['count'] / len(Y)*100,0)\n",
    "\n",
    "ax = plt.axes()\n",
    "plt.bar(diag_df.index, diag_df['count'], align = 'center')\n",
    "ax.set_xticks([0,1,2,3,4])\n",
    "\n",
    "# Spine formatting\n",
    "ax.set_facecolor(color='white')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_color('cornflowerblue')\n",
    "ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "# Tick formatting\n",
    "ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "ax.tick_params(axis='x', which='both', color='cornflowerblue', \n",
    "               colors = 'gray', rotation = 30)\n",
    "\n",
    "# Grid formatting\n",
    "ax.grid(False)\n",
    "vals = ax.get_yticks()\n",
    "for tick in vals:\n",
    "    ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='cornflowerblue', zorder=1)\n",
    "\n",
    "# Setting text labels according to the count of df\n",
    "rects = ax.patches\n",
    "percentages = diag_df['%']\n",
    "counts = diag_df['count']\n",
    "\n",
    "for rect, label, cnt in zip(rects, percentages, counts):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, height + 0.01, str(label) + '%',\n",
    "            ha='center', va='bottom', color = 'gray',weight='normal')\n",
    "    height = rect.get_height() + 200\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, height + 0.01, cnt,\n",
    "            ha='center', va='bottom', color = 'royalblue',weight='bold')\n",
    "    \n",
    "# Set title\n",
    "plt.suptitle(\"Classification\", x = 0.123, y = 1.06, ha = 'left', weight='bold', color = 'royalblue', \n",
    "             size=20)\n",
    "\n",
    "# Set title\n",
    "ax.set_title(\"Initial Distribution\", weight='normal', color = 'dimgray', \n",
    "             style = 'italic', pad=14, loc='left', size=15)\n",
    "\n",
    "# Set x-axis label\n",
    "ax.set_xlabel(\"Class\", labelpad=20, weight='bold', size=10, color='gray')\n",
    "\n",
    "# Set y-axis label\n",
    "ax.set_ylabel(\"Counts\", labelpad=20, weight='bold', size=10, color='gray')\n",
    "\n",
    "diag_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eec91d-3538-43b2-b155-f0cdcbd8e80f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">Class Imbalance Sections </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5718fdc2-1608-4a43-97ff-f5b485ef060e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# seed randoms in one place\n",
    "\n",
    "random.seed(5678)\n",
    "np.random.seed(5678)\n",
    "tf.random.set_seed(5678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a146dbc7-7c6e-4d9c-81bd-eeac725cb266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Fix Data Imbalance using SMOTE\n",
    "\n",
    "orig_shape = X.shape\n",
    "X = np.reshape(X, (orig_shape[0], orig_shape[1] * orig_shape[2] * orig_shape[3]))\n",
    "oversample = SMOTE()\n",
    "print('X before smote: ', X.shape)\n",
    "print('Y before smote: ', Y.shape)\n",
    "X, Y = oversample.fit_resample(X, Y)\n",
    "X = np.reshape(X, (X.shape[0], orig_shape[1], orig_shape[2], orig_shape[3]))\n",
    "print('X after smote: ', X.shape)\n",
    "print('Y after smote: ', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10cb9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diagnoses = pd.Series(Y)\n",
    "diagnoses = diagnoses.replace([0, 1, 2, 3], label_names)\n",
    "diag_df = pd.DataFrame({'count': diagnoses.value_counts()})\n",
    "diag_df['%'] = round(diag_df['count'] / len(Y)*100,0)\n",
    "diag_df.index.str.strip()\n",
    "diag_df = diag_df.reindex(label_names)\n",
    "\n",
    "ax = plt.axes()\n",
    "plt.bar(diag_df.index, diag_df['count'], align = 'center')\n",
    "ax.set_xticks([0,1,2,3,4])\n",
    "\n",
    "# Spine formatting\n",
    "ax.set_facecolor(color='white')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_color('cornflowerblue')\n",
    "ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "# Tick formatting\n",
    "ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "ax.tick_params(axis='x', which='both', color='cornflowerblue', \n",
    "               colors = 'gray', rotation = 30)\n",
    "\n",
    "# Grid formatting\n",
    "ax.grid(False)\n",
    "vals = ax.get_yticks()\n",
    "for tick in vals:\n",
    "    ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='cornflowerblue', zorder=1)\n",
    "\n",
    "# Setting text labels according to the count of df\n",
    "rects = ax.patches\n",
    "percentages = diag_df['%']\n",
    "counts = diag_df['count']\n",
    "\n",
    "for rect, label, cnt in zip(rects, percentages, counts):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, height + 0.01, str(label) + '%',\n",
    "            ha='center', va='bottom', color = 'gray',weight='normal')\n",
    "    height = rect.get_height() + 200\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, height + 0.01, cnt,\n",
    "            ha='center', va='bottom', color = 'royalblue',weight='bold')\n",
    "    \n",
    "# Set title\n",
    "plt.suptitle(\"Classification\", x = 0.123, y = 1.06, ha = 'left', weight='bold', color = 'royalblue', \n",
    "             size=20)\n",
    "\n",
    "# Set title\n",
    "ax.set_title(\"After Imbalance Treatment\", weight='normal', color = 'dimgray', \n",
    "             style = 'italic', pad=14, loc='left', size=15)\n",
    "\n",
    "# Set x-axis label\n",
    "ax.set_xlabel(\"Class\", labelpad=20, weight='bold', size=10, color='gray')\n",
    "\n",
    "# Set y-axis label\n",
    "ax.set_ylabel(\"Counts\", labelpad=20, weight='bold', size=10, color='gray')\n",
    "\n",
    "diag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3489355b-e826-4679-9d86-3643832dc349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shuffle input\n",
    "#np.random.seed(0)\n",
    "indices = np.arange(X.shape[0])\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "X = X[shuffled_indices]\n",
    "Y = Y[shuffled_indices]\n",
    "\n",
    "# Use a ~80/20 train/test split.\n",
    "idx = (int)(X.shape[0] * 0.8)\n",
    "X_train = X[:idx]\n",
    "Y_train = Y[:idx]\n",
    "X_test = X[idx:]\n",
    "Y_test = Y[idx:]\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb84f565",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">PCA</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5888f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = X_train.reshape(X_train.shape[0], (X_train.shape[1] * X_train.shape[2] * X_train.shape[3]))\n",
    "X_test_pca = X_test.reshape(X_test.shape[0], (X_test.shape[1] * X_test.shape[2] * X_test.shape[3]))\n",
    "\n",
    "# Creating a principal component analysis model\n",
    "# Enough components to keep around 85% of the variance in the original data \n",
    "pca = PCA(n_components = 225)\n",
    "\n",
    "# Feeding the independent variables to the PCA model\n",
    "X_train_pca = pca.fit_transform(X_train_pca)\n",
    "X_test_pca = pca.transform(X_test_pca)\n",
    "\n",
    "print(X_train_pca.shape)\n",
    "print(X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25990ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485dd76-8878-4669-a869-fc1c087420e2",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">End Class Imbalance Section</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6cb9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing 5 examples of each class\n",
    "\n",
    "classes = 4\n",
    "\n",
    "examples = 5\n",
    "\n",
    "pic_counter = [0] * classes\n",
    "i = 0\n",
    "\n",
    "# Create a figure with subplots.\n",
    "# As a grid of # product_classes x # examples_per_each\n",
    "\n",
    "fig, axs = plt.subplots(nrows = classes, ncols= examples, figsize=(10,classes * 2))\n",
    "\n",
    "# Keep searching until we find all we need\n",
    "\n",
    "while sum(pic_counter) < (classes * examples):\n",
    "    \n",
    "    image = X[i]\n",
    "    label = int(Y[i])\n",
    "    label_name = label_names[label]\n",
    "    \n",
    "    # Add a picture to the grid \n",
    "    # if we haven't find all the examples we need\n",
    "    # for that product class\n",
    "    if pic_counter[label] < examples:\n",
    "        axs[label][pic_counter[label]].imshow(image.astype(\"uint8\"))\n",
    "        axs[label][pic_counter[label]].set_title(label_name)\n",
    "        axs[label][pic_counter[label]].axis('off')\n",
    "        pic_counter[label] += 1\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_performance_metrics(model, x_test, y_test):\n",
    "    #Record other performance metrics\n",
    "    x_test_predict = model.predict(x_test, verbose=0)\n",
    "    x_predict_classes =np.argmax(x_test_predict, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, x_predict_classes)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, x_predict_classes, average='macro')\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, x_predict_classes, average='macro')\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, x_predict_classes, average='macro')\n",
    "    #auc = roc_auc_score(Y_test, yhat_probs, multi_class='ovr')\n",
    "    \n",
    "    metrics = {\n",
    "        \"accuracy\": format(accuracy, '.4f'),\n",
    "        \"precision\": format(precision, '.4f'),\n",
    "        \"recall\": format(recall, '.4f'),\n",
    "        \"f1_score\": format(f1, '.4f')\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c25a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_performance_metrics_cnn_lstm(model, x_test, y_test):\n",
    "    #Record other performance metrics\n",
    "    x_test_predict = model.predict(x_test, verbose=0)\n",
    "\n",
    "    x_test_predict_shape = x_test_predict.shape\n",
    "    x_test_predict = np.reshape(x_test_predict, (x_test_predict_shape[0] * x_test_predict_shape[1], x_test_predict_shape[2]))\n",
    "\n",
    "    y_test_seq_flat = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1]))\n",
    "\n",
    "    x_predict_classes = np.argmax(x_test_predict, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_seq_flat, x_predict_classes)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test_seq_flat, x_predict_classes, average='macro')\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test_seq_flat, x_predict_classes, average='macro')\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test_seq_flat, x_predict_classes, average='macro')\n",
    "    \n",
    "    metrics = {\n",
    "        \"accuracy\": format(accuracy, '.4f'),\n",
    "        \"precision\": format(precision, '.4f'),\n",
    "        \"recall\": format(recall, '.4f'),\n",
    "        \"f1_score\": format(f1, '.4f')\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1e63be",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">Multi-Class Logistic Regression </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d33bbf-3f25-4243-a77f-b02ad3bb1d20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_logreg_model(n_classes = 4, \n",
    "                       learning_rate = 0.01, \n",
    "                       activation = 'softmax'):\n",
    "    \"\"\"Build a multi-class logistic regression model using Keras.\n",
    "\n",
    "    Args:\n",
    "        n_classes: Number of classes in the dataset\n",
    "        learning_rate: The desired learning rate for SGD.\n",
    "\n",
    "    Returns:\n",
    "        model: A tf.keras model (graph).\n",
    "    \"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    print('Activation function: ' + activation)\n",
    "    print('Optimizer: SGD')\n",
    "    print('Learning Rate: ' + str(learning_rate))\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(\n",
    "      units = n_classes,\n",
    "      activation = activation\n",
    "    ))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n",
    "\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', \n",
    "                  optimizer = optimizer, \n",
    "                  metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90829cc4-094c-4b82-ad4f-79b06d1a3b72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_logreg(x_train,\n",
    "                              y_train,\n",
    "                              x_test,\n",
    "                              y_test,\n",
    "                              activation = 'softmax',\n",
    "                              optimizer = 'SGD',\n",
    "                              learning_rate = 0.001,\n",
    "                              num_epochs = 20, \n",
    "                              verb = False):\n",
    "    \n",
    "    print('Number of Epochs: ' + str(num_epochs))\n",
    "    \n",
    "    model = build_logreg_model(n_classes = len(label_names), \n",
    "                               learning_rate = learning_rate,\n",
    "                               activation = activation)\n",
    "\n",
    "    history = model.fit(\n",
    "        x = x_train,\n",
    "        y = y_train,\n",
    "        epochs = num_epochs,\n",
    "        batch_size=64,\n",
    "        verbose = verb,\n",
    "        validation_split=0.1)\n",
    "\n",
    "    hist = history.history\n",
    "    train_accuracy = hist['accuracy']\n",
    "    val_accuracy = hist['val_accuracy']\n",
    "    num_params = model.count_params()\n",
    "    test_predictions = np.argmax(model.predict(x_test, verbose = verb), axis=-1)\n",
    "    test_accuracy = model.evaluate(x = x_test, y = y_test, verbose = verb,\n",
    "                               return_dict=True)['accuracy']\n",
    "  \n",
    "    # Create a confusion matrix as a 2D array.\n",
    "    confusion_matrix = tf.math.confusion_matrix(y_test, test_predictions)\n",
    "    \n",
    "    ## Plot mean CV accuracies for Tree Depth\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(train_accuracy, label = \"Training Accuracy\", \n",
    "         color = 'royalblue', marker = '.', lw = 1)\n",
    "    ax.plot(val_accuracy, label = \"Validation Accuracy\", \n",
    "             color = 'mediumblue', marker = 'D', lw = 2)\n",
    "    \n",
    "    # Spine formatting\n",
    "    ax.set_facecolor(color='white')\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_color('cornflowerblue')\n",
    "    ax.spines['bottom'].set_color('cornflowerblue')\n",
    "    \n",
    "    # Tick formatting\n",
    "    ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "    ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "    ax.set_xticks(range(num_epochs + 1))\n",
    "    \n",
    "    # Grid formatting\n",
    "    ax.grid(False)\n",
    "    vals = ax.get_yticks()\n",
    "    for tick in vals:\n",
    "        ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "    \n",
    "    # Set title\n",
    "    plt.suptitle(\"Accuracy vs. Number of Epochs\", x = 0.123, y = 1, \n",
    "                 ha = 'left', weight='bold', color = 'mediumblue', \n",
    "                 size = 18)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title(\"Training and Validation\", weight='normal', color = 'dimgray', \n",
    "                 style = 'italic', pad=10, loc='left', size=15)\n",
    "    \n",
    "    ax.legend(loc = 4, fontsize = 'medium', \n",
    "              shadow = True,\n",
    "              edgecolor = 'blue',\n",
    "              labelcolor = ['royalblue','mediumblue'], \n",
    "              facecolor = 'ivory')\n",
    "    \n",
    "    ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "    ax.set_ylabel('Accuracy', color = 'gray', weight = 'bold')\n",
    "    ax.set_ylim(top = 1.01)\n",
    "\n",
    "    # Use a heatmap plot to display Confusion Matrix.\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax = sns.heatmap(confusion_matrix, annot = True, fmt = '.3g', cmap = 'Blues',\n",
    "                     xticklabels = label_names, yticklabels = label_names, cbar = False)\n",
    "    \n",
    "    # Add axis labels.\n",
    "    ax.tick_params(axis='x', which='both', length=0, colors = 'gray', rotation = 90)\n",
    "    ax.set_xlabel('Predicted Label', color = 'gray', weight = 'bold')\n",
    "    ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "    ax.set_ylabel('True Label', color = 'gray', weight = 'bold')\n",
    "\n",
    "    ax.set_title('CONFUSION MATRIX', \n",
    "                 weight='bold', color = 'mediumblue', pad=14, loc='left', size=18)\n",
    "\n",
    "    ax.text(x = 4, y = -0.22, ha = 'right',\n",
    "            s = 'TEST ACC: ' + str(round(test_accuracy*100,2)) + '%',\n",
    "            color = 'mediumblue', weight='bold')\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    return [test_accuracy, num_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c21210",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ind = ['Experiment_' + str(i) for i in range(1,5)]\n",
    "acts = (['sigmoid'] * 2 + ['softmax'] * 2)\n",
    "opts = (['SGD'] * 4)\n",
    "rates = ([0.01] + [0.001]) * 2\n",
    "epchs = [20] * 4\n",
    "params = [0] * 4\n",
    "accs = [0] * 4\n",
    "\n",
    "experiments_lrdf = pd.DataFrame({'ACTIVATION': acts, \n",
    "                                 'OPTIMIZER': opts, \n",
    "                                 'LEARNING RATE': rates,\n",
    "                                 'EPOCHS': epchs, \n",
    "                                 '# PARAMETERS': params,\n",
    "                                 'TEST ACCURACY': accs,\n",
    "                                 '# PARAMETERS (PCA)': params,\n",
    "                                 'TEST ACCURACY (PCA)': accs}, \n",
    "                                index = exp_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1b5c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range (1,len(experiments_lrdf.index)+1):\n",
    "    print('Experiment_' + str(i) + '\\n')\n",
    "    accu, param = train_and_evaluate_logreg(X_train, Y_train, X_test, Y_test,\n",
    "                                            activation = experiments_lrdf.loc['Experiment_' + str(i), 'ACTIVATION'], \n",
    "                                            optimizer = experiments_lrdf.loc['Experiment_' + str(i), 'OPTIMIZER'], \n",
    "                                            learning_rate = experiments_lrdf.loc['Experiment_' + str(i), 'LEARNING RATE'])\n",
    "\n",
    "    experiments_lrdf.loc['Experiment_' + str(i), '# PARAMETERS'] = param\n",
    "    experiments_lrdf.loc['Experiment_' + str(i), 'TEST ACCURACY'] = accu\n",
    "    \n",
    "    print('Experiment_' + str(i) + '_PCA\\n')\n",
    "    accu_pca, param_pca = train_and_evaluate_logreg(X_train_pca, Y_train, X_test_pca, Y_test,\n",
    "                                            activation = experiments_lrdf.loc['Experiment_' + str(i), 'ACTIVATION'], \n",
    "                                            optimizer = experiments_lrdf.loc['Experiment_' + str(i), 'OPTIMIZER'], \n",
    "                                            learning_rate = experiments_lrdf.loc['Experiment_' + str(i), 'LEARNING RATE'])\n",
    "\n",
    "    experiments_lrdf.loc['Experiment_' + str(i), '# PARAMETERS (PCA)'] = param_pca\n",
    "    experiments_lrdf.loc['Experiment_' + str(i), 'TEST ACCURACY (PCA)'] = accu_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab3a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_lrdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108420f4",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">K-Means Clustering</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b580d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def kmean_models(init_clusters,  \n",
    "                 x_train, \n",
    "                 y_train,\n",
    "                 x_test,\n",
    "                 y_test):\n",
    "    \n",
    "    totl_rows = 2\n",
    "    totl_cols = 5\n",
    "    \n",
    "    exp_ind = ['Experiment_' + str(i) for i in range(1,(totl_rows * totl_cols)+1)]\n",
    "    kmean_df = pd.DataFrame(index = exp_ind)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows = totl_rows, ncols = totl_cols, figsize = (20, 8))\n",
    "\n",
    "    for i in range(0, totl_rows * totl_cols):\n",
    "        row = math.trunc(i/totl_cols)\n",
    "        col = i%totl_cols\n",
    "\n",
    "        num_clusters = init_clusters ** (i)\n",
    "\n",
    "        kmean = KMeans(n_clusters = num_clusters, \n",
    "                       init = 'k-means++',\n",
    "                       random_state = 0)\n",
    "\n",
    "        kmean.fit(X_train_pca, Y_train)\n",
    "\n",
    "        kmean_train = kmean.predict(X_train_pca)\n",
    "\n",
    "        kmean_translator = pd.DataFrame({'CLUSTER': kmean_train, \n",
    "                                         'LABEL': Y_train})\n",
    "\n",
    "        translator = pd.Series.tolist(kmean_translator.groupby(['CLUSTER']).agg(pd.Series.mode)['LABEL'])\n",
    "        \n",
    "        kmean_train_pred = kmean.predict(X_train_pca)\n",
    "        kmean_train_pred = pd.Series(kmean_train_pred)\n",
    "        kmean_train_pred = kmean_train_pred.replace(range(0, num_clusters), translator)\n",
    "        train_acc = sum(kmean_train_pred == Y_train)/len(Y_train)\n",
    "        \n",
    "        kmean_predictions = kmean.predict(X_test_pca)\n",
    "        kmean_predictions = pd.Series(kmean_predictions)\n",
    "        kmean_predictions = kmean_predictions.replace(range(0, num_clusters), translator)\n",
    "        test_acc = sum(kmean_predictions == Y_test)/len(Y_test)\n",
    "\n",
    "        kmean_confusion_matrix = tf.math.confusion_matrix(Y_test, kmean_predictions)\n",
    "\n",
    "        sns.heatmap(ax = axs[row][col], data = kmean_confusion_matrix, annot=True, fmt='.3g', cmap='Blues',\n",
    "                        xticklabels = (label_names if row + 1 == totl_rows else 'auto'), \n",
    "                        yticklabels = (label_names if col == 0 else 'auto'), cbar=False)\n",
    "\n",
    "        # Add axis labels.\n",
    "        if row + 1 == totl_rows:\n",
    "            axs[row][col].set_xlabel('Predicted Label', color = 'gray', weight = 'bold')\n",
    "            axs[row][col].tick_params(axis='x', which='both', length=0, colors = 'gray')\n",
    "        else:\n",
    "            axs[row][col].set_xticks([])\n",
    "\n",
    "        if col == 0:\n",
    "            axs[row][col].set_ylabel('True Label', color = 'gray', weight = 'bold')\n",
    "            axs[row][col].tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        else:\n",
    "            axs[row][col].set_yticks([])\n",
    "\n",
    "        axs[row][col].set_title(\"# CLUSTERS: \" + str(num_clusters) + '    TEST ACC: ' + str(round(test_acc*100,2)) + '%', \n",
    "                                    weight='bold', color = 'mediumblue', pad=14, loc='center', size=12)\n",
    "        \n",
    "        kmean_df.loc['Experiment_' + str(i + 1), '# CLUSTERS'] = num_clusters\n",
    "        kmean_df.loc['Experiment_' + str(i + 1), 'TRAIN ACCURACY'] = train_acc\n",
    "        kmean_df.loc['Experiment_' + str(i + 1), 'TEST ACCURACY'] = test_acc\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return kmean_df\n",
    "\n",
    "## Plot accuracies vs. k values\n",
    "experiments_kmean_df = kmean_models(2, X_train_pca, Y_train, X_test_pca, Y_test)\n",
    "\n",
    "experiments_kmean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5353807c",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">Nearest Neighbors </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb1f0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Create helper function for plotting the training accuracy vs. \n",
    "## cross-validation accuracy plot with various depths\n",
    "def knn_acc_plot(start: int, \n",
    "                 end: int, \n",
    "                 x_train, \n",
    "                 y_train,\n",
    "                 x_test,\n",
    "                 y_test):\n",
    "    ## Set k range and initialize df\n",
    "    k_range = range(start, end)\n",
    "    exp_ind = ['Experiment_' + str(i) for i in range(1,end-start+1)]\n",
    "    knn_df = pd.DataFrame(index = exp_ind)\n",
    "    totl_cols = 4\n",
    "    totl_rows = math.ceil((end-start-1)/totl_cols)\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows = totl_rows, ncols= totl_cols, figsize = (5 * totl_cols, 4 * totl_rows))\n",
    "    i = 0\n",
    "    \n",
    "    for k in k_range:\n",
    "        row = math.trunc(i/totl_cols)\n",
    "        col = i%totl_cols\n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(x_train, y_train)\n",
    "        accuracy = knn.score(x_train, y_train)\n",
    "        scores = cross_val_score(knn, x_train, y_train, cv=5, scoring='accuracy')\n",
    "        test_accuracy = knn.score(x_test, y_test)\n",
    "        knn_predictions = knn.predict(x_test)\n",
    "        knn_confusion_matrix = tf.math.confusion_matrix(y_test, knn_predictions)\n",
    "        \n",
    "        sns.heatmap(ax = axs[row][col], data = knn_confusion_matrix, annot=True, fmt='.3g', cmap='Blues',\n",
    "                    xticklabels = (label_names if row + 1 == totl_rows else 'auto'), \n",
    "                    yticklabels = (label_names if col == 0 else 'auto'), cbar=False)\n",
    "\n",
    "        # Add axis labels.\n",
    "        if row + 1 == totl_rows:\n",
    "            axs[row][col].set_xlabel('Predicted Label', color = 'gray', weight = 'bold')\n",
    "            axs[row][col].tick_params(axis='x', which='both', length=0, colors = 'gray')\n",
    "        else:\n",
    "            axs[row][col].set_xticks([])\n",
    "            \n",
    "        if col == 0:\n",
    "            axs[row][col].set_ylabel('True Label', color = 'gray', weight = 'bold')\n",
    "            axs[row][col].tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        else:\n",
    "            axs[row][col].set_yticks([])\n",
    "        \n",
    "        axs[row][col].set_title(\"NEIGHBORS (k): \" + str(k) + '    TEST ACC: ' + str(round(test_accuracy*100,2)) + '%', \n",
    "                                weight='bold', color = 'mediumblue', pad=14, loc='center', size=12)\n",
    "        \n",
    "        knn_df.loc['Experiment_' + str(i + 1), 'NEIGHBORS (k)'] = k\n",
    "        knn_df.loc['Experiment_' + str(i + 1), 'CV ACCURACY'] = scores.mean()\n",
    "        knn_df.loc['Experiment_' + str(i + 1), 'TRAIN ACCURACY'] = accuracy.mean()\n",
    "        knn_df.loc['Experiment_' + str(i + 1), 'TEST ACCURACY'] = test_accuracy\n",
    "        \n",
    "        i += 1\n",
    "    plt.show()\n",
    "\n",
    "    ## Plot mean CV accuracies for k\n",
    "    ax = plt.axes()\n",
    "    plt.plot(k_range, knn_df['TRAIN ACCURACY'], label = \"Training Accuracy\", \n",
    "         color = 'royalblue', marker = '.', lw = 1)\n",
    "    plt.plot(k_range, knn_df['CV ACCURACY'], label = \"Cross-Val Accuracy\", \n",
    "             color = 'mediumblue', marker = 'D', lw = 2)\n",
    "    \n",
    "    # Spine formatting\n",
    "    ax.set_facecolor(color='white')\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_color('cornflowerblue')\n",
    "    ax.spines['bottom'].set_color('cornflowerblue')\n",
    "    \n",
    "    # Tick formatting\n",
    "    ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "    ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "    ax.set_xticks(k_range)\n",
    "    \n",
    "    # Grid formatting\n",
    "    ax.grid(False)\n",
    "    vals = ax.get_yticks()\n",
    "    for tick in vals:\n",
    "        ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "    \n",
    "    # Set title\n",
    "    plt.suptitle(\"Mean Accuracies vs. k after Initial Split\", x = 0.123, y = 1.06, \n",
    "                 ha = 'left', weight='bold', color = 'mediumblue', \n",
    "                 size = 18)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title(\"Training and Cross-Validation\", weight='normal', color = 'dimgray', \n",
    "                 style = 'italic', pad=14, loc='left', size=15)\n",
    "    \n",
    "    ax.legend(loc = 3, fontsize = 'medium', \n",
    "              shadow = True,\n",
    "              edgecolor = 'blue',\n",
    "              labelcolor = ['royalblue','mediumblue'], \n",
    "              facecolor = 'ivory')\n",
    "    \n",
    "    ax.set_xlabel('Neighbors (k)', color = 'gray', weight = 'bold')\n",
    "    ax.set_ylabel('Mean Accuracy', color = 'gray', weight = 'bold')\n",
    "    ax.set_ylim(top = 1.01)\n",
    "    plt.show()\n",
    "    \n",
    "    return knn_df\n",
    "\n",
    "## Plot accuracies vs. k values\n",
    "experiments_knn_df = knn_acc_plot(1, 21, X_train_pca, Y_train, X_test_pca, Y_test)\n",
    "\n",
    "experiments_knn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2fa250",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">Decision Trees</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbd6694",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Create helper function for plotting the training accuracy vs. \n",
    "## cross-validation accuracy plot with various depths\n",
    "def dt_acc_plot(start: int, \n",
    "                end: int, \n",
    "                x_train, \n",
    "                y_train,\n",
    "                x_test,\n",
    "                y_test):\n",
    "    ## Set depth range and initialize lists\n",
    "    t_depth = range(start, end)\n",
    "    exp_ind = ['Experiment_' + str(i) for i in range(1,end-start+1)]\n",
    "    tree_df = pd.DataFrame(index = exp_ind)\n",
    "    totl_cols = 4\n",
    "    totl_rows = math.ceil((end-start-1)/totl_cols)\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows = totl_rows, ncols= totl_cols, figsize = (5 * totl_cols, 4 * totl_rows))\n",
    "    i = 0\n",
    "    \n",
    "    for lvl in t_depth:\n",
    "        row = math.trunc(i/totl_cols)\n",
    "        col = i%totl_cols\n",
    "        dtree = tree.DecisionTreeClassifier(random_state = 0, max_depth = lvl)\n",
    "        dtree.fit(x_train, y_train)\n",
    "        accuracy = dtree.score(x_train, y_train)\n",
    "        scores = cross_val_score(dtree, x_train, y_train, cv=5, scoring='accuracy')\n",
    "        test_accuracy = dtree.score(x_test, y_test)\n",
    "        tree_predictions = dtree.predict(x_test)\n",
    "        tree_confusion_matrix = tf.math.confusion_matrix(y_test, tree_predictions)\n",
    "        \n",
    "        sns.heatmap(ax = axs[row][col], data = tree_confusion_matrix, annot=True, fmt='.3g', cmap='Blues',\n",
    "                    xticklabels = (label_names if row + 1 == totl_rows else 'auto'), \n",
    "                    yticklabels = (label_names if col == 0 else 'auto'), cbar=False)\n",
    "\n",
    "        # Add axis labels.\n",
    "        if row + 1 == totl_rows:\n",
    "            axs[row][col].set_xlabel('Predicted Label', color = 'gray', weight = 'bold')\n",
    "            axs[row][col].tick_params(axis='x', which='both', length=0, colors = 'gray')\n",
    "        else:\n",
    "            axs[row][col].set_xticks([])\n",
    "            \n",
    "        if col == 0:\n",
    "            axs[row][col].set_ylabel('True Label', color = 'gray', weight = 'bold')\n",
    "            axs[row][col].tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        else:\n",
    "            axs[row][col].set_yticks([])\n",
    "        \n",
    "        axs[row][col].set_title(\"TREE DEPTH: \" + str(lvl) + '    TEST ACC: ' + str(round(test_accuracy*100,2)) + '%', \n",
    "                                weight='bold', color = 'mediumblue', pad=14, loc='center', size=12)\n",
    "        \n",
    "        tree_df.loc['Experiment_' + str(i + 1), 'MAX DEPTH'] = lvl\n",
    "        tree_df.loc['Experiment_' + str(i + 1), 'CV ACCURACY'] = scores.mean()\n",
    "        tree_df.loc['Experiment_' + str(i + 1), 'TRAIN ACCURACY'] = accuracy.mean()\n",
    "        tree_df.loc['Experiment_' + str(i + 1), 'TEST ACCURACY'] = test_accuracy\n",
    "        \n",
    "        i += 1\n",
    "    plt.show()\n",
    "    \n",
    "    ## Plot mean CV accuracies for Tree Depth\n",
    "    ax = plt.axes()\n",
    "    plt.plot(t_depth, tree_df['TRAIN ACCURACY'], label = \"Training Accuracy\", \n",
    "         color = 'royalblue', marker = '.', lw = 1)\n",
    "    plt.plot(t_depth, tree_df['CV ACCURACY'], label = \"Cross-Val Accuracy\", \n",
    "             color = 'mediumblue', marker = 'D', lw = 2)\n",
    "    \n",
    "    # Spine formatting\n",
    "    ax.set_facecolor(color='white')\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_color('cornflowerblue')\n",
    "    ax.spines['bottom'].set_color('cornflowerblue')\n",
    "    \n",
    "    # Tick formatting\n",
    "    ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "    ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "    ax.set_xticks(t_depth)\n",
    "    \n",
    "    # Grid formatting\n",
    "    ax.grid(False)\n",
    "    vals = ax.get_yticks()\n",
    "    for tick in vals:\n",
    "        ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "    \n",
    "    # Set title\n",
    "    plt.suptitle(\"Mean Accuracies vs. Decision Tree Depth\", x = 0.123, y = 1.06, \n",
    "                 ha = 'left', weight='bold', color = 'mediumblue', \n",
    "                 size = 18)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title(\"Training and Cross-Validation\", weight='normal', color = 'dimgray', \n",
    "                 style = 'italic', pad=14, loc='left', size=15)\n",
    "    \n",
    "    ax.legend(loc = 4, fontsize = 'medium', \n",
    "              shadow = True,\n",
    "              edgecolor = 'blue',\n",
    "              labelcolor = ['royalblue','mediumblue'], \n",
    "              facecolor = 'ivory')\n",
    "    \n",
    "    ax.set_xlabel('Tree Depth', color = 'gray', weight = 'bold')\n",
    "    ax.set_ylabel('Mean Accuracy', color = 'gray', weight = 'bold')\n",
    "    ax.set_ylim(top = 1.04)\n",
    "    plt.show()\n",
    "    \n",
    "    return tree_df\n",
    "\n",
    "## Plot accuracies vs. k values\n",
    "experiments_tree_df = dt_acc_plot(1, 21, X_train_pca, Y_train, X_test_pca, Y_test)\n",
    "\n",
    "experiments_tree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e930c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT THIS TO GET A PICTURE OF THE TREE\n",
    "\n",
    "dtree = tree.DecisionTreeClassifier(random_state = 0, max_depth = 5)\n",
    "dtree.fit(X_train_pca, Y_train)\n",
    "\n",
    "tree_predictions = dtree.predict(X_test_pca)\n",
    "\n",
    "print('TestAccuracy: %1.4f' %dtree.score(X_test_pca, Y_test))\n",
    "\n",
    "tree.plot_tree(dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf83ee",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">Random Forest</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ede2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create helper function for plotting the training accuracy vs. \n",
    "## cross-validation accuracy plot with various depths\n",
    "def rf_acc_plot(start: int, \n",
    "                end: int, \n",
    "                x_train, \n",
    "                y_train,\n",
    "                x_test,\n",
    "                y_test):\n",
    "    ## Set depth range and initialize lists\n",
    "    rf_depth = range(start, end)\n",
    "    tree_scores = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    exp_ind = ['Experiment_' + str(i) for i in range(1,end-start+1)]\n",
    "    rfor_df = pd.DataFrame(index = exp_ind)\n",
    "    totl_cols = 4\n",
    "    totl_rows = math.ceil((end-start-1)/totl_cols)\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows = totl_rows, ncols= totl_cols, figsize = (5 * totl_cols, 4 * totl_rows))\n",
    "    i = 0\n",
    "    \n",
    "    for lvl in rf_depth:\n",
    "        row = math.trunc(i/totl_cols)\n",
    "        col = i%totl_cols\n",
    "        rfor = RandomForestClassifier(random_state = 0, max_depth = lvl)\n",
    "        rfor.fit(x_train, y_train)\n",
    "        accuracy = rfor.score(x_train, y_train)\n",
    "        scores = cross_val_score(rfor, x_train, y_train, cv = 5, scoring='accuracy')\n",
    "        test_accuracy = rfor.score(x_test, y_test)\n",
    "        forest_predictions = rfor.predict(x_test)\n",
    "        forest_confusion_matrix = tf.math.confusion_matrix(y_test, forest_predictions)\n",
    "        \n",
    "        sns.heatmap(ax = axs[row][col], data = forest_confusion_matrix, annot=True, fmt='.3g', cmap='Blues',\n",
    "                    xticklabels = (label_names if row + 1 == totl_rows else 'auto'), \n",
    "                    yticklabels = (label_names if col == 0 else 'auto'), cbar=False)\n",
    "\n",
    "        # Add axis labels.\n",
    "        if row + 1 == totl_rows:\n",
    "            axs[row][col].set_xlabel('Predicted Label', color = 'gray', weight = 'bold')\n",
    "            axs[row][col].tick_params(axis='x', which='both', length=0, colors = 'gray')\n",
    "        else:\n",
    "            axs[row][col].set_xticks([])\n",
    "            \n",
    "        if col == 0:\n",
    "            axs[row][col].set_ylabel('True Label', color = 'gray', weight = 'bold')\n",
    "            axs[row][col].tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        else:\n",
    "            axs[row][col].set_yticks([])\n",
    "        \n",
    "        axs[row][col].set_title(\"FOREST DEPTH: \" + str(lvl) + '    TEST ACC: ' + str(round(test_accuracy*100,2)) + '%', \n",
    "                                weight='bold', color = 'mediumblue', pad=14, loc='center', size=12)\n",
    "        \n",
    "        rfor_df.loc['Experiment_' + str(i + 1), 'MAX DEPTH'] = lvl\n",
    "        rfor_df.loc['Experiment_' + str(i + 1), 'CV ACCURACY'] = scores.mean()\n",
    "        rfor_df.loc['Experiment_' + str(i + 1), 'TRAIN ACCURACY'] = accuracy.mean()\n",
    "        rfor_df.loc['Experiment_' + str(i + 1), 'TEST ACCURACY'] = test_accuracy\n",
    "        \n",
    "        i += 1\n",
    "    plt.show()\n",
    "    \n",
    "    ## Plot mean CV accuracies for depth\n",
    "    \n",
    "    ax = plt.axes()\n",
    "    plt.plot(rf_depth, rfor_df['TRAIN ACCURACY'], label = \"Training Accuracy\", \n",
    "         color = 'royalblue', marker = '.', lw = 1)\n",
    "    plt.plot(rf_depth, rfor_df['CV ACCURACY'], label = \"Cross-Val Accuracy\", \n",
    "             color = 'mediumblue', marker = 'D', lw = 2)\n",
    "    \n",
    "    # Spine formatting\n",
    "    ax.set_facecolor(color='white')\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_color('cornflowerblue')\n",
    "    ax.spines['bottom'].set_color('cornflowerblue')\n",
    "    \n",
    "    # Tick formatting\n",
    "    ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "    ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "    ax.set_xticks(rf_depth)\n",
    "    \n",
    "    # Grid formatting\n",
    "    ax.grid(False)\n",
    "    vals = ax.get_yticks()\n",
    "    for tick in vals:\n",
    "        ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "    \n",
    "    # Set title\n",
    "    plt.suptitle(\"Mean Accuracies vs. Random Forest Depth\", x = 0.123, y = 1.06, \n",
    "                 ha = 'left', weight='bold', color = 'mediumblue', \n",
    "                 size = 18)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title(\"Training and Cross-Validation\", weight='normal', color = 'dimgray', \n",
    "                 style = 'italic', pad=14, loc='left', size=15)\n",
    "    \n",
    "    ax.legend(loc = 4, fontsize = 'medium', \n",
    "              shadow = True,\n",
    "              edgecolor = 'blue',\n",
    "              labelcolor = ['royalblue','mediumblue'], \n",
    "              facecolor = 'ivory')\n",
    "    \n",
    "    ax.set_xlabel('Forest Depth', color = 'gray', weight = 'bold')\n",
    "    ax.set_ylabel('Mean Accuracy', color = 'gray', weight = 'bold')\n",
    "    ax.set_ylim(top = 1.04)\n",
    "    plt.show()\n",
    "    \n",
    "    return rfor_df\n",
    "\n",
    "## Plot accuracies vs. k values\n",
    "experiments_rfor_df = rf_acc_plot(1, 13, X_train_pca, Y_train, X_test_pca, Y_test)\n",
    "\n",
    "experiments_rfor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91724dfb",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">Neural Networks </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e742fa-45a7-4233-ac6b-ae9b1f469eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network with hidden layers\n",
    "\n",
    "def build_nn_model(n_classes,\n",
    "                   hidden_layer_sizes=[],\n",
    "                   activation='relu',\n",
    "                   optimizer='SGD',\n",
    "                   learning_rate=0.01):\n",
    "    \"\"\"Build a multi-class logistic regression model using Keras.\n",
    "\n",
    "    Args:\n",
    "        n_classes: Number of output classes in the dataset.\n",
    "        hidden_layer_sizes: A list with the number of units in each hidden layer.\n",
    "        activation: The activation function to use for the hidden layers.\n",
    "        optimizer: The optimizer to use (SGD, Adam).\n",
    "        learning_rate: The desired learning rate for the optimizer.\n",
    "\n",
    "    Returns:\n",
    "        model: A tf.keras model (graph).\n",
    "    \"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(5678)\n",
    "    tf.random.set_seed(5678)\n",
    "    random.seed(5678)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # flatten the 128x128x3 images into 1-D vectors\n",
    "    model.add(keras.layers.Flatten())\n",
    "  \n",
    "    # add the specified hidden layers with the specified activation\n",
    "    i = 1\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        lay_name = 'Hidden_' + str(i)\n",
    "        model.add(tf.keras.layers.Dense(units = hidden_layer_size,\n",
    "                                        activation = activation,\n",
    "                                        name = lay_name))\n",
    "        print('Hidden Layer ' + str(i) + ' size: ' + str(hidden_layer_size))\n",
    "        i += 1\n",
    "  \n",
    "    #Output layer. Since we are doing multi-class classification, use softmax for the activation\n",
    "    model.add(tf.keras.layers.Dense(units = n_classes,\n",
    "                                    activation = 'softmax',\n",
    "                                    name = 'Output'))\n",
    "    \n",
    "    print('Activation function: ' + activation)\n",
    "\n",
    "    if optimizer == 'SGD':\n",
    "        model_opt = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n",
    "        print('Optimizer: SGD')\n",
    "    elif optimizer == 'Adam':\n",
    "        model_opt = keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "        print('Optimizer: Adam')\n",
    "    else:\n",
    "        model_opt = optimizer\n",
    "        print('Optimizer: ' + optimizer)\n",
    "        \n",
    "    print('Learning Rate: ' + str(learning_rate))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer = model_opt, metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd354d1-8630-4443-b5e7-e61761414dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_nn(x_train,\n",
    "                          y_train,\n",
    "                          x_test,\n",
    "                          y_test,\n",
    "                          hidden_layer_sizes=[],\n",
    "                          activation='relu',\n",
    "                          optimizer='Adam',\n",
    "                          learning_rate=0.01,\n",
    "                          num_epochs=20, \n",
    "                          verb = False):\n",
    "\n",
    "    # Build the model.\n",
    "    model = build_nn_model(n_classes=4,\n",
    "                           hidden_layer_sizes=hidden_layer_sizes,\n",
    "                           activation=activation,\n",
    "                           optimizer=optimizer,\n",
    "                           learning_rate=learning_rate)\n",
    "\n",
    "    # Train the model.\n",
    "    history = model.fit(\n",
    "        x = x_train,\n",
    "        y = y_train,\n",
    "        epochs = num_epochs,\n",
    "        batch_size = 64, \n",
    "        verbose = verb,\n",
    "        validation_split = 0.1)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Retrieve the training metrics (after each train epoch) and the final test\n",
    "    # accuracy.\n",
    "    hist = history.history\n",
    "    train_accuracy = hist['accuracy']\n",
    "    val_accuracy = hist['val_accuracy']\n",
    "    \n",
    "    test_accuracy = model.evaluate(x = x_test, y = y_test, verbose = verb,\n",
    "                                   return_dict=True)['accuracy']\n",
    "\n",
    "    num_params = model.count_params()\n",
    "\n",
    "    test_predictions = np.argmax(model.predict(x_test, verbose = verb), axis=-1)\n",
    "  \n",
    "    # Create a confusion matrix as a 2D array.\n",
    "    confusion_matrix = tf.math.confusion_matrix(y_test, test_predictions)\n",
    "    \n",
    "    ## Plot mean CV accuracies for Tree Depth\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(train_accuracy, label = \"Training Accuracy\", \n",
    "         color = 'royalblue', marker = '.', lw = 1)\n",
    "    ax.plot(val_accuracy, label = \"Validation Accuracy\", \n",
    "             color = 'mediumblue', marker = 'D', lw = 2)\n",
    "    \n",
    "    # Spine formatting\n",
    "    ax.set_facecolor(color='white')\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_color('cornflowerblue')\n",
    "    ax.spines['bottom'].set_color('cornflowerblue')\n",
    "    \n",
    "    # Tick formatting\n",
    "    ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "    ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "    ax.set_xticks(range(num_epochs + 1))\n",
    "    \n",
    "    # Grid formatting\n",
    "    ax.grid(False)\n",
    "    vals = ax.get_yticks()\n",
    "    for tick in vals:\n",
    "        ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "    \n",
    "    # Set title\n",
    "    plt.suptitle(\"Accuracy vs. Number of Epochs\", x = 0.123, y = 1, \n",
    "                 ha = 'left', weight='bold', color = 'mediumblue', \n",
    "                 size = 18)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title(\"Training and Validation\", weight='normal', color = 'dimgray', \n",
    "                 style = 'italic', pad=10, loc='left', size=15)\n",
    "    \n",
    "    ax.legend(loc = 4, fontsize = 'medium', \n",
    "              shadow = True,\n",
    "              edgecolor = 'blue',\n",
    "              labelcolor = ['royalblue','mediumblue'], \n",
    "              facecolor = 'ivory')\n",
    "    \n",
    "    ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "    ax.set_ylabel('Accuracy', color = 'gray', weight = 'bold')\n",
    "    ax.set_ylim(top = 1.01)\n",
    "\n",
    "    # Use a heatmap plot to display it.\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax = sns.heatmap(confusion_matrix, annot = True, fmt = '.3g', cmap = 'Blues',\n",
    "                     xticklabels = label_names, yticklabels = label_names, cbar = False)\n",
    "    \n",
    "    # Add axis labels.\n",
    "    ax.tick_params(axis='x', which='both', length=0, colors = 'gray', rotation = 90)\n",
    "    ax.set_xlabel('Predicted Label', color = 'gray', weight = 'bold')\n",
    "    ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "    ax.set_ylabel('True Label', color = 'gray', weight = 'bold')\n",
    "\n",
    "    ax.set_title('CONFUSION MATRIX', \n",
    "                 weight='bold', color = 'mediumblue', pad=14, loc='left', size=18)\n",
    "\n",
    "    ax.text(x = 4, y = -0.22, ha = 'right',\n",
    "            s = 'TEST ACC: ' + str(round(test_accuracy*100,2)) + '%',\n",
    "            color = 'mediumblue', weight='bold')\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    metrics = compute_model_performance_metrics(model, x_test, y_test)\n",
    "    \n",
    "    train_acc = float(hist['accuracy'][len(hist)-1])\n",
    "    val_acc = float(hist['val_accuracy'][len(hist)-1])\n",
    "    \n",
    "    metrics[\"train_accuracy\"] = format(train_acc, '.4f')\n",
    "    metrics[\"val_accuracy\"] = format(val_acc, '.4f')\n",
    "\n",
    "    return [test_accuracy, num_params, metrics]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52499a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a Dataframe with all the Neural Network experiments' information\n",
    "\n",
    "exp_ind = ['Experiment_' + str(i) for i in range(1,7)]\n",
    "acts = (['relu'] + ['tanh']* 2 + ['relu'] * 3)\n",
    "opts = (['Adam'] + ['SGD'] * 3 + ['Adam'] * 2)\n",
    "sizes = [[]] + [[128]] + [[256 , 128]] + ([[128]]) * 2 + [[256 , 128]]\n",
    "rates = [0.01] * 3 + [0.0001] + [0.001] + [0.0001]\n",
    "epchs = [21] + [5] + [20] * 4\n",
    "params = [0] * 6\n",
    "accs = [0] * 6\n",
    "\n",
    "experiments_nndf = pd.DataFrame({'ACTIVATION': acts, \n",
    "                                 'OPTIMIZER': opts, \n",
    "                                 'HIDDEN SIZES': sizes, \n",
    "                                 'LEARNING RATE': rates,\n",
    "                                 'EPOCHS': epchs, \n",
    "                                 '# PARAMETERS': params,\n",
    "                                 'TEST ACCURACY': accs, \n",
    "                                 '# PARAMETERS (PCA)': params,\n",
    "                                 'TEST ACCURACY (PCA)': accs}, \n",
    "                                index = exp_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003642cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range (1,len(experiments_nndf.index)+1):\n",
    "    print('Experiment_' + str(i) + '\\n')\n",
    "    accu, param, metrics = train_and_evaluate_nn(X_train, Y_train, X_test, Y_test,\n",
    "                                        hidden_layer_sizes = experiments_nndf.loc['Experiment_' + str(i), 'HIDDEN SIZES'], \n",
    "                                        activation = experiments_nndf.loc['Experiment_' + str(i), 'ACTIVATION'], \n",
    "                                        optimizer = experiments_nndf.loc['Experiment_' + str(i), 'OPTIMIZER'], \n",
    "                                        learning_rate = experiments_nndf.loc['Experiment_' + str(i), 'LEARNING RATE'], \n",
    "                                        num_epochs = experiments_nndf.loc['Experiment_' + str(i), 'EPOCHS'])\n",
    "    \n",
    "    experiments_nndf.loc['Experiment_' + str(i), '# PARAMETERS'] = param\n",
    "    experiments_nndf.loc['Experiment_' + str(i), 'TEST ACCURACY'] = accu\n",
    "    \n",
    "    \n",
    "    print('Experiment_' + str(i) + '_PCA\\n')\n",
    "    accu_pca, param_pca, metrics = train_and_evaluate_nn(X_train_pca, Y_train, X_test_pca, Y_test,\n",
    "                                        hidden_layer_sizes = experiments_nndf.loc['Experiment_' + str(i), 'HIDDEN SIZES'], \n",
    "                                        activation = experiments_nndf.loc['Experiment_' + str(i), 'ACTIVATION'], \n",
    "                                        optimizer = experiments_nndf.loc['Experiment_' + str(i), 'OPTIMIZER'], \n",
    "                                        learning_rate = experiments_nndf.loc['Experiment_' + str(i), 'LEARNING RATE'], \n",
    "                                        num_epochs = experiments_nndf.loc['Experiment_' + str(i), 'EPOCHS'])\n",
    "    \n",
    "    experiments_nndf.loc['Experiment_' + str(i), '# PARAMETERS (PCA)'] = param_pca\n",
    "    experiments_nndf.loc['Experiment_' + str(i), 'TEST ACCURACY (PCA)'] = accu_pca\n",
    "    experiments_nndf.loc['Experiment_' + str(i), 'TRAIN ACCURACY'] = metrics[\"train_accuracy\"]\n",
    "    experiments_nndf.loc['Experiment_' + str(i), 'VAL ACCURACY'] = metrics[\"val_accuracy\"]\n",
    "    experiments_nndf.loc['Experiment_' + str(i), 'PRECISON'] = metrics[\"precision\"]\n",
    "    experiments_nndf.loc['Experiment_' + str(i), 'RECALL'] = metrics[\"recall\"]\n",
    "    experiments_nndf.loc['Experiment_' + str(i), 'F1 SCORE'] = metrics[\"f1_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df20e22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiments_nndf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34ba90-c703-4702-a5fc-67298e314f58",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">CNN</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_sq = X_train_pca.reshape(X_train_pca.shape[0], int(np.sqrt(X_train_pca.shape[1])), int(np.sqrt(X_train_pca.shape[1])), 1)\n",
    "X_test_pca_sq = X_test_pca.reshape(X_test_pca.shape[0], int(np.sqrt(X_test_pca.shape[1])), int(np.sqrt(X_test_pca.shape[1])), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c247328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape,\n",
    "                    kern_sz = (5,5), \n",
    "                    stri_sz = (1,1), \n",
    "                    pool_sz = (2,2),\n",
    "                    lear_rt = 0.001,\n",
    "                    optimiz = 'Adam'):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(5678)\n",
    "    tf.random.set_seed(5678)\n",
    "    random.seed(5678)\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # add first convolution layer to the model\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters = 32,\n",
    "        kernel_size = kern_sz,\n",
    "        strides = stri_sz,\n",
    "        padding = 'same',\n",
    "        data_format = 'channels_last',\n",
    "        name = 'conv_1',\n",
    "        activation = 'relu'))\n",
    "\n",
    "\n",
    "    # add a max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size = pool_sz,\n",
    "        name = 'pool_1'))\n",
    "\n",
    "\n",
    "    # add second convolutional layer\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = kern_sz,\n",
    "        strides = stri_sz,\n",
    "        padding = 'same',\n",
    "        name = 'conv_2',\n",
    "        activation = 'relu'))\n",
    "\n",
    "    # add second max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will further reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.MaxPool2D(\n",
    "        pool_size = pool_sz, \n",
    "        name='pool_2'))\n",
    "\n",
    "\n",
    "    # add a fully connected layer (need to flatten the output of the previous layers first)\n",
    "    model.add(tf.keras.layers.Flatten()) \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units = 1024,\n",
    "        name = 'fc_1', \n",
    "        activation = 'relu'))\n",
    "\n",
    "    # add dropout layer\n",
    "    model.add(tf.keras.layers.Dropout(\n",
    "        rate = 0.5))\n",
    "\n",
    "    # add the last fully connected layer\n",
    "    # this last layer sets the activation function to \"None\" in order to output the logits \n",
    "    # note that passing activation = \"sigmoid\" will return class memembership probabilities but\n",
    "    # in TensorFlow logits are prefered for numerical stability\n",
    "    # set units=1 to get a single output unit (remember it's a binary classification problem)\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units = 4,\n",
    "        name = 'fc_2',\n",
    "        activation = None))\n",
    "\n",
    "\n",
    "    # build model and print summary\n",
    "    model.build(input_shape = input_shape)\n",
    "    \n",
    "    if optimiz == 'SGD':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate = lear_rt)\n",
    "    elif optimiz == 'Adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = lear_rt)\n",
    "    else:\n",
    "        opt = optimiz\n",
    "        print('Optimizer: ' + optimizer)\n",
    "        \n",
    "    model.compile(optimizer = opt,\n",
    "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), #set from_ligits=True because our last layer does not apply sigmoid\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d121bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_n_run_cnn_model(x_train,\n",
    "                          y_train,\n",
    "                          x_test,\n",
    "                          y_test,\n",
    "                          kern_sz = (5,5), \n",
    "                          stri_sz = (1,1), \n",
    "                          pool_sz = (2,2),\n",
    "                          lear_rt = 0.001,\n",
    "                          optimiz = 'Adam', \n",
    "                          num_epochs = 20,\n",
    "                          verb=False, \n",
    "                          graphing = True):\n",
    "\n",
    "    model = build_cnn_model(x_train.shape, kern_sz, stri_sz, pool_sz, lear_rt, optimiz) \n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(x_train, \n",
    "                        y_train,\n",
    "                        epochs = num_epochs, \n",
    "                        validation_split=0.1,\n",
    "                        verbose = verb)\n",
    "    \n",
    "    hist = history.history\n",
    "    if (graphing):\n",
    "        x_arr = np.arange(len(hist['loss'])) + 1\n",
    "        \n",
    "        ## Plot mean CV accuracies for Tree Depth\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        ax.plot(x_arr, hist['loss'], '-o', label='Train loss', \n",
    "             color = 'salmon', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss', \n",
    "                 color = 'firebrick', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Loss vs. Number of Epochs\", weight='bold', color = 'firebrick', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 1, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['salmon','firebrick'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Loss', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(bottom = -0.01)\n",
    "        \n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        ax.plot(x_arr, hist['accuracy'], '-o', label = \"Training Accuracy\", \n",
    "             color = 'royalblue', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_accuracy'], '--<', label = \"Validation Accuracy\", \n",
    "                 color = 'mediumblue', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Accuracy vs. Number of Epochs\", weight='bold', color = 'mediumblue', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 4, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['royalblue','mediumblue'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Accuracy', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(top = 1.01)\n",
    "        \n",
    "        plt.subplots_adjust(wspace=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    test_accuracy = model.evaluate(x_test, y_test, verbose=0, return_dict=True)['accuracy']\n",
    "    \n",
    "    metrics = compute_model_performance_metrics(model, x_test, y_test)\n",
    "    \n",
    "    train_acc = float(hist['accuracy'][len(hist)-1])\n",
    "    val_acc = float(hist['val_accuracy'][len(hist)-1])\n",
    "    \n",
    "    metrics[\"train_accuracy\"] = format(train_acc, '.4f')\n",
    "    metrics[\"val_accuracy\"] = format(val_acc, '.4f')\n",
    "    \n",
    "    num_params = model.count_params()\n",
    "    \n",
    "    return [test_accuracy, num_params, metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c254545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a Dataframe with all the experiments' information\n",
    "\n",
    "exp_ind = ['Experiment_' + str(i) for i in range(1,7)]\n",
    "kern_sz = [(5,5)] + [(3,3)] + [(5,5)] * 4\n",
    "strides = [(1,1)] * 2 + [(2,2)] + [(1,1)] * 3\n",
    "pool_sz = [(2,2)] * 3 + [(3,3)] + [(2,2)] * 2\n",
    "lear_rt = [0.001] * 4 + [0.01] + [0.001]\n",
    "optimiz = ['Adam'] * 5 + ['SGD']\n",
    "\n",
    "experiments_cnn_df = pd.DataFrame({'kernel size': kern_sz, \n",
    "                               'strides': strides, \n",
    "                               'pool size': pool_sz, \n",
    "                               'learning rate': lear_rt, \n",
    "                               'optimizer': optimiz},\n",
    "                             index = exp_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd8d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_cnn_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e6691",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range (1,len(experiments_cnn_df.index)+1):\n",
    "    print('Experiment_' + str(i) + '\\n')\n",
    "    print(experiments_cnn_df.loc['Experiment_'+ str(i),'kernel size':'optimizer'], '\\n')\n",
    "    \n",
    "    accu , param, metrics = build_n_run_cnn_model(X_train_pca_sq, Y_train, X_test_pca_sq, Y_test,\n",
    "                                 kern_sz = experiments_cnn_df.loc['Experiment_' + str(i), 'kernel size'], \n",
    "                                 stri_sz = experiments_cnn_df.loc['Experiment_' + str(i), 'strides'],\n",
    "                                 pool_sz = experiments_cnn_df.loc['Experiment_' + str(i), 'pool size'],\n",
    "                                 lear_rt = experiments_cnn_df.loc['Experiment_' + str(i), 'learning rate'],\n",
    "                                 optimiz = experiments_cnn_df.loc['Experiment_' + str(i), 'optimizer'])\n",
    "\n",
    "    experiments_cnn_df.loc['Experiment_' + str(i), '# PARAMETERS'] = param\n",
    "    experiments_cnn_df.loc['Experiment_' + str(i), 'TEST ACCURACY'] = accu\n",
    "    experiments_cnn_df.loc['Experiment_' + str(i), 'TRAIN ACCURACY'] = metrics[\"train_accuracy\"]\n",
    "    experiments_cnn_df.loc['Experiment_' + str(i), 'VAL ACCURACY'] = metrics[\"val_accuracy\"]\n",
    "    #experiments_cnn_df.loc['Experiment_' + str(i), 'ACCURACY'] = metrics[\"accuracy\"]\n",
    "    experiments_cnn_df.loc['Experiment_' + str(i), 'PRECISON'] = metrics[\"precision\"]\n",
    "    experiments_cnn_df.loc['Experiment_' + str(i), 'RECALL'] = metrics[\"recall\"]\n",
    "    experiments_cnn_df.loc['Experiment_' + str(i), 'F1 SCORE'] = metrics[\"f1_score\"]\n",
    "    \n",
    "    print('Test Accuracy: %1.4f' % accu + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16041276",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_cnn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d352ce",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\"> CNN + LSTM</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape before X_train_pca_sq', X_train_pca_sq.shape)\n",
    "print('Shape Y_train', Y_train.shape)\n",
    "\n",
    "#reshape to time-series sequence of size 10\n",
    "X_train_seq = np.reshape(X_train_pca_sq, (int(X_train_pca_sq.shape[0]/10), 10, X_train_pca_sq.shape[1], X_train_pca_sq.shape[2], X_train_pca_sq.shape[3]))\n",
    "Y_train_seq = np.reshape(Y_train, (int(Y_train.shape[0]/10), 10))\n",
    "\n",
    "X_test_seq = np.reshape(X_test_pca_sq, (int(X_test_pca_sq.shape[0]/10), 10, X_test_pca_sq.shape[1], X_test_pca_sq.shape[2], X_test_pca_sq.shape[3]))\n",
    "Y_test_seq = np.reshape(Y_test, (int(Y_test.shape[0]/10), 10))\n",
    "\n",
    "print('Shape X_train_seq', X_train_seq.shape)\n",
    "print('Shape Y_train_seq', Y_train_seq.shape)\n",
    "\n",
    "print('Shape X_test_seq', X_test_seq.shape)\n",
    "print('Shape Y_test_seq', Y_test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa95cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnnlstm_model(input_shape,\n",
    "                         kern_sz = (5,5), \n",
    "                         stri_sz = (1,1), \n",
    "                         pool_sz = (2,2),\n",
    "                         lear_rt = 0.001,\n",
    "                         optimiz = 'Adam'):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # add first convolution layer to the model\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(\n",
    "        filters = 32,\n",
    "        kernel_size = kern_sz,\n",
    "        strides = stri_sz,\n",
    "        padding = 'same',\n",
    "        data_format = 'channels_last',\n",
    "        name = 'conv_1',\n",
    "        activation = 'relu')))\n",
    "\n",
    "    # add a max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D(\n",
    "        pool_size = pool_sz,\n",
    "        name = 'pool_1')))\n",
    "\n",
    "\n",
    "    # add second convolutional layer\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = kern_sz,\n",
    "        strides = stri_sz,\n",
    "        padding = 'same',\n",
    "        name = 'conv_2',\n",
    "        activation = 'relu')))\n",
    "\n",
    "    # add second max pooling layer with pool size (2,2) and strides of 2\n",
    "    # (this will further reduce the spatial dimensions by half)\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D(\n",
    "        pool_size = pool_sz, \n",
    "        name='pool_2')))\n",
    "\n",
    "\n",
    "    # add a fully connected layer (need to flatten the output of the previous layers first)\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()))\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(\n",
    "        units = 1024,\n",
    "        name = 'fc_1', \n",
    "        activation = 'relu')))\n",
    "\n",
    "    # add dropout layer\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(rate = 0.5)))\n",
    "\n",
    "    #Add LSTM layers\n",
    "    model.add(tf.keras.layers.LSTM(1024, return_sequences=True))\n",
    "    model.add(tf.keras.layers.Dense(units=4, name='fc_2', activation=None))\n",
    "\n",
    "    model.build(input_shape=input_shape)\n",
    "    \n",
    "    if optimiz == 'SGD':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate = lear_rt)\n",
    "    elif optimiz == 'Adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = lear_rt)\n",
    "    else:\n",
    "        opt = optimiz\n",
    "        print('Optimizer: ' + optimizer)\n",
    "    \n",
    "    model.compile(optimizer=opt, \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), #set from_ligits=True because our last layer does not apply sigmoid\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9086a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildrun_cnnlstm_model(x_train,\n",
    "                          y_train,\n",
    "                          x_test,\n",
    "                          y_test,\n",
    "                          kern_sz = (5,5), \n",
    "                          stri_sz = (1,1), \n",
    "                          pool_sz = (2,2),\n",
    "                          lear_rt = 0.001,\n",
    "                          optimiz = 'Adam', \n",
    "                          num_epochs = 20,\n",
    "                          verb=False, \n",
    "                          graphing = True):\n",
    "\n",
    "    model = build_cnnlstm_model(x_train.shape, kern_sz, stri_sz, pool_sz, lear_rt, optimiz) \n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(x_train, \n",
    "                        y_train,\n",
    "                        epochs = num_epochs, \n",
    "                        validation_split=0.1,\n",
    "                        verbose = verb)\n",
    "    \n",
    "    hist = history.history\n",
    "    if (graphing):\n",
    "        x_arr = np.arange(len(hist['loss'])) + 1\n",
    "        \n",
    "        ## Plot mean CV accuracies for Tree Depth\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        ax.plot(x_arr, hist['loss'], '-o', label='Train loss', \n",
    "             color = 'salmon', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss', \n",
    "                 color = 'firebrick', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Loss vs. Number of Epochs\", weight='bold', color = 'firebrick', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 1, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['salmon','firebrick'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Loss', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(bottom = -0.01)\n",
    "        \n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        ax.plot(x_arr, hist['accuracy'], '-o', label = \"Training Accuracy\", \n",
    "             color = 'royalblue', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_accuracy'], '--<', label = \"Validation Accuracy\", \n",
    "                 color = 'mediumblue', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Accuracy vs. Number of Epochs\", weight='bold', color = 'mediumblue', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 4, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['royalblue','mediumblue'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Accuracy', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(top = 1.01)\n",
    "        \n",
    "        plt.subplots_adjust(wspace=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    test_accuracy = model.evaluate(x_test, y_test, verbose=0, return_dict=True)['accuracy']\n",
    "    \n",
    "    metrics = compute_model_performance_metrics_cnn_lstm(model, x_test, y_test)\n",
    "    \n",
    "    train_acc = float(hist['accuracy'][len(hist)-1])\n",
    "    val_acc = float(hist['val_accuracy'][len(hist)-1])\n",
    "    \n",
    "    metrics[\"train_accuracy\"] = format(train_acc, '.4f')\n",
    "    metrics[\"val_accuracy\"] = format(val_acc, '.4f')\n",
    "    \n",
    "    num_params = model.count_params()\n",
    "    \n",
    "    return [test_accuracy, num_params, metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a Dataframe with all the experiments' information\n",
    "\n",
    "exp_ind = ['Experiment_' + str(i) for i in range(1,7)]\n",
    "kern_sz = [(5,5)] + [(3,3)] + [(5,5)] * 4\n",
    "strides = [(1,1)] * 2 + [(2,2)] + [(1,1)] * 3\n",
    "pool_sz = [(2,2)] * 3 + [(3,3)] + [(2,2)] * 2\n",
    "lear_rt = [0.001] * 4 + [0.01] + [0.001]\n",
    "optimiz = ['Adam'] * 5 + ['SGD']\n",
    "\n",
    "experiments_cnnlstm_df = pd.DataFrame({'kernel size': kern_sz, \n",
    "                                       'strides': strides, \n",
    "                                       'pool size': pool_sz, \n",
    "                                       'learning rate': lear_rt, \n",
    "                                       'optimizer': optimiz},\n",
    "                                     index = exp_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e46098",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range (1,len(experiments_cnnlstm_df.index)+1):\n",
    "    print('Experiment_' + str(i) + '\\n')\n",
    "    print(experiments_cnnlstm_df.loc['Experiment_'+ str(i),'kernel size':'optimizer'], '\\n')\n",
    "    \n",
    "    accu , param, metrics = buildrun_cnnlstm_model(X_train_seq, Y_train_seq, X_test_seq, Y_test_seq,\n",
    "                                 kern_sz = experiments_cnnlstm_df.loc['Experiment_' + str(i), 'kernel size'], \n",
    "                                 stri_sz = experiments_cnnlstm_df.loc['Experiment_' + str(i), 'strides'],\n",
    "                                 pool_sz = experiments_cnnlstm_df.loc['Experiment_' + str(i), 'pool size'],\n",
    "                                 lear_rt = experiments_cnnlstm_df.loc['Experiment_' + str(i), 'learning rate'],\n",
    "                                 optimiz = experiments_cnnlstm_df.loc['Experiment_' + str(i), 'optimizer'])\n",
    "\n",
    "    experiments_cnnlstm_df.loc['Experiment_' + str(i), '# PARAMETERS'] = param\n",
    "    experiments_cnnlstm_df.loc['Experiment_' + str(i), 'TEST ACCURACY'] = accu\n",
    "    experiments_cnnlstm_df.loc['Experiment_' + str(i), 'TRAIN ACCURACY'] = metrics[\"train_accuracy\"]\n",
    "    experiments_cnnlstm_df.loc['Experiment_' + str(i), 'VAL ACCURACY'] = metrics[\"val_accuracy\"]\n",
    "    #experiments_cnnlstm_df.loc['Experiment_' + str(i), 'ACCURACY'] = metrics[\"accuracy\"]\n",
    "    experiments_cnnlstm_df.loc['Experiment_' + str(i), 'PRECISON'] = metrics[\"precision\"]\n",
    "    experiments_cnnlstm_df.loc['Experiment_' + str(i), 'RECALL'] = metrics[\"recall\"]\n",
    "    experiments_cnnlstm_df.loc['Experiment_' + str(i), 'F1 SCORE'] = metrics[\"f1_score\"]\n",
    "    \n",
    "    print('Test Accuracy: %1.4f' % accu + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a45aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_cnnlstm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ab085",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">RNN</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce590b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_rnn_model(n_classes,\n",
    "                    activation= 'relu',\n",
    "                    optimizer= 'Adam',\n",
    "                    learning_rate=0.01):\n",
    "    \n",
    "    print('Activation function: ' + activation)\n",
    "    print('Optimizer: ' + optimizer)\n",
    "    print('Learning Rate: ' + str(learning_rate))\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(None,15)))\n",
    "\n",
    "    model.add(\n",
    "        tf.keras.layers.SimpleRNN(225, return_sequences = True, activation = activation)\n",
    "    )\n",
    "\n",
    "\n",
    "    model.add(\n",
    "        tf.keras.layers.SimpleRNN(225, activation = activation)\n",
    "    )\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(n_classes))\n",
    "\n",
    "    if optimizer == 'SGD':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    else:\n",
    "        opt = optimiz\n",
    "        print('Optimizer: ' + optimizer)\n",
    "\n",
    "    model.compile(optimizer = opt,\n",
    "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), #set from_ligits=True because our last layer does not apply sigmoid\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c653621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_n_run_rnn_model(x_train,\n",
    "                          y_train,\n",
    "                          x_test,\n",
    "                          y_test,\n",
    "                          activ= 'relu',\n",
    "                          lear_rt = 0.001,\n",
    "                          optimiz = 'Adam', \n",
    "                          num_epochs = 10,\n",
    "                          verb = False, \n",
    "                          graphing = True):\n",
    "    \n",
    "    print('Number of Epochs: ' + str(num_epochs))\n",
    "    \n",
    "    model = build_rnn_model(len(label_names), activ, optimiz, lear_rt) \n",
    "    history = model.fit(x_train, \n",
    "                        y_train,\n",
    "                        batch_size = 64,\n",
    "                        epochs = num_epochs, \n",
    "                        validation_split=0.1,\n",
    "                        verbose = verb)\n",
    "    \n",
    "    hist = history.history\n",
    "    if (graphing):\n",
    "        x_arr = np.arange(len(hist['loss'])) + 1\n",
    "        \n",
    "        ## Plot mean CV accuracies for Tree Depth\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        ax.plot(x_arr, hist['loss'], '-o', label='Train loss', \n",
    "             color = 'salmon', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss', \n",
    "                 color = 'firebrick', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Loss vs. Number of Epochs\", weight='bold', color = 'firebrick', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 1, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['salmon','firebrick'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Loss', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(bottom = -0.01)\n",
    "        \n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        ax.plot(x_arr, hist['accuracy'], '-o', label = \"Training Accuracy\", \n",
    "             color = 'royalblue', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_accuracy'], '--<', label = \"Validation Accuracy\", \n",
    "                 color = 'mediumblue', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Accuracy vs. Number of Epochs\", weight='bold', color = 'mediumblue', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 4, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['royalblue','mediumblue'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Accuracy', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(top = 1.01)\n",
    "        \n",
    "        plt.subplots_adjust(wspace=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    test_accuracy = model.evaluate(x_test, y_test, verbose=verb, return_dict=True)['accuracy']\n",
    "    \n",
    "    metrics = compute_model_performance_metrics(model, x_test, y_test)\n",
    "    \n",
    "    train_acc = float(hist['accuracy'][len(hist)-1])\n",
    "    val_acc = float(hist['val_accuracy'][len(hist)-1])\n",
    "    \n",
    "    metrics[\"train_accuracy\"] = format(train_acc, '.4f')\n",
    "    metrics[\"val_accuracy\"] = format(val_acc, '.4f')\n",
    "    \n",
    "    num_params = model.count_params()\n",
    "    \n",
    "    return [test_accuracy, num_params, metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf0032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a Dataframe with all the experiments' information\n",
    "\n",
    "exp_ind = ['Experiment_' + str(i) for i in range(1,7)]\n",
    "activ = ['relu'] * 2 + ['tanh'] * 2 +  ['relu'] * 2\n",
    "lear_rt = ([0.01] + [0.001]) * 3\n",
    "optimiz = ['Adam'] *4 + ['SGD'] * 2\n",
    "\n",
    "experiments_rnn_df = pd.DataFrame({'activation': activ, \n",
    "                                   'learning rate': lear_rt, \n",
    "                                   'optimizer': optimiz},\n",
    "                             index = exp_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc1a21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range (1,len(experiments_rnn_df.index)+1):\n",
    "    print('Experiment_' + str(i) + '\\n')\n",
    "    \n",
    "    accu , param, metrics = build_n_run_rnn_model(X_train_pca_sq, Y_train, X_test_pca_sq, Y_test,\n",
    "                                                  activ= experiments_rnn_df.loc['Experiment_' + str(i), 'activation'],\n",
    "                                                  lear_rt = experiments_rnn_df.loc['Experiment_' + str(i), 'learning rate'],\n",
    "                                                  optimiz = experiments_rnn_df.loc['Experiment_' + str(i), 'optimizer'])\n",
    "\n",
    "    experiments_rnn_df.loc['Experiment_' + str(i), '# PARAMETERS'] = param\n",
    "    experiments_rnn_df.loc['Experiment_' + str(i), 'TEST ACCURACY'] = accu\n",
    "    experiments_rnn_df.loc['Experiment_' + str(i), 'TRAIN ACCURACY'] = metrics[\"train_accuracy\"]\n",
    "    experiments_rnn_df.loc['Experiment_' + str(i), 'VAL ACCURACY'] = metrics[\"val_accuracy\"]\n",
    "    #experiments_cnn_df.loc['Experiment_' + str(i), 'ACCURACY'] = metrics[\"accuracy\"]\n",
    "    experiments_rnn_df.loc['Experiment_' + str(i), 'PRECISON'] = metrics[\"precision\"]\n",
    "    experiments_rnn_df.loc['Experiment_' + str(i), 'RECALL'] = metrics[\"recall\"]\n",
    "    experiments_rnn_df.loc['Experiment_' + str(i), 'F1 SCORE'] = metrics[\"f1_score\"]\n",
    "    \n",
    "    print('Test Accuracy: %1.4f' % accu + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766b7a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_rnn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8713aa61",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">GRU</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru_model(n_classes,\n",
    "                    activation= 'relu',\n",
    "                    optimizer= 'Adam',\n",
    "                    learning_rate=0.01):\n",
    "    \n",
    "    print('Activation function: ' + activation)\n",
    "    print('Optimizer: ' + optimizer)\n",
    "    print('Learning Rate: ' + str(learning_rate))\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(None,15)))\n",
    "\n",
    "    model.add(\n",
    "        tf.keras.layers.GRU(225, return_sequences = True, activation = activation)\n",
    "    )\n",
    "\n",
    "\n",
    "    model.add(\n",
    "        tf.keras.layers.GRU(225, activation = activation)\n",
    "    )\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(n_classes))\n",
    "\n",
    "    if optimizer == 'SGD':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    else:\n",
    "        opt = optimiz\n",
    "        print('Optimizer: ' + optimizer)\n",
    "\n",
    "    model.compile(optimizer = opt,\n",
    "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), #set from_ligits=True because our last layer does not apply sigmoid\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_n_run_gru_model(x_train,\n",
    "                          y_train,\n",
    "                          x_test,\n",
    "                          y_test,\n",
    "                          activ= 'relu',\n",
    "                          lear_rt = 0.001,\n",
    "                          optimiz = 'Adam', \n",
    "                          num_epochs = 10,\n",
    "                          verb = False, \n",
    "                          graphing = True):\n",
    "    \n",
    "    print('Number of Epochs: ' + str(num_epochs))\n",
    "    \n",
    "    model = build_gru_model(len(label_names), activ, optimiz, lear_rt) \n",
    "    history = model.fit(x_train, \n",
    "                        y_train,\n",
    "                        batch_size = 64,\n",
    "                        epochs = num_epochs, \n",
    "                        validation_split=0.1,\n",
    "                        verbose = verb)\n",
    "    \n",
    "    hist = history.history\n",
    "    if (graphing):\n",
    "        x_arr = np.arange(len(hist['loss'])) + 1\n",
    "        \n",
    "        ## Plot mean CV accuracies for Tree Depth\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        ax.plot(x_arr, hist['loss'], '-o', label='Train loss', \n",
    "             color = 'salmon', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss', \n",
    "                 color = 'firebrick', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Loss vs. Number of Epochs\", weight='bold', color = 'firebrick', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 1, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['salmon','firebrick'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Loss', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(bottom = -0.01)\n",
    "        \n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        ax.plot(x_arr, hist['accuracy'], '-o', label = \"Training Accuracy\", \n",
    "             color = 'royalblue', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_accuracy'], '--<', label = \"Validation Accuracy\", \n",
    "                 color = 'mediumblue', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Accuracy vs. Number of Epochs\", weight='bold', color = 'mediumblue', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 4, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['royalblue','mediumblue'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Accuracy', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(top = 1.01)\n",
    "        \n",
    "        plt.subplots_adjust(wspace=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    test_accuracy = model.evaluate(x_test, y_test, verbose=verb, return_dict=True)['accuracy']\n",
    "    \n",
    "    metrics = compute_model_performance_metrics(model, x_test, y_test)\n",
    "    \n",
    "    train_acc = float(hist['accuracy'][len(hist)-1])\n",
    "    val_acc = float(hist['val_accuracy'][len(hist)-1])\n",
    "    \n",
    "    metrics[\"train_accuracy\"] = format(train_acc, '.4f')\n",
    "    metrics[\"val_accuracy\"] = format(val_acc, '.4f')\n",
    "    \n",
    "    num_params = model.count_params()\n",
    "    \n",
    "    return [test_accuracy, num_params, metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a158bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a Dataframe with all the experiments' information\n",
    "\n",
    "exp_ind = ['Experiment_' + str(i) for i in range(1,7)]\n",
    "activ = ['relu'] * 2 + ['tanh'] * 2 +  ['relu'] * 2\n",
    "lear_rt = ([0.01] + [0.001]) * 3\n",
    "optimiz = ['Adam'] *4 + ['SGD'] * 2\n",
    "\n",
    "experiments_gru_df = pd.DataFrame({'activation': activ, \n",
    "                                   'learning rate': lear_rt, \n",
    "                                   'optimizer': optimiz},\n",
    "                             index = exp_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3be225",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range (1,len(experiments_gru_df.index)+1):\n",
    "    print('Experiment_' + str(i) + '\\n')\n",
    "    \n",
    "    accu , param, metrics = build_n_run_gru_model(X_train_pca_sq, Y_train, X_test_pca_sq, Y_test,\n",
    "                                                  activ= experiments_gru_df.loc['Experiment_' + str(i), 'activation'],\n",
    "                                                  lear_rt = experiments_gru_df.loc['Experiment_' + str(i), 'learning rate'],\n",
    "                                                  optimiz = experiments_gru_df.loc['Experiment_' + str(i), 'optimizer'])\n",
    "\n",
    "    experiments_gru_df.loc['Experiment_' + str(i), '# PARAMETERS'] = param\n",
    "    experiments_gru_df.loc['Experiment_' + str(i), 'TEST ACCURACY'] = accu\n",
    "    experiments_gru_df.loc['Experiment_' + str(i), 'TRAIN ACCURACY'] = metrics[\"train_accuracy\"]\n",
    "    experiments_gru_df.loc['Experiment_' + str(i), 'VAL ACCURACY'] = metrics[\"val_accuracy\"]\n",
    "    #experiments_cnn_df.loc['Experiment_' + str(i), 'ACCURACY'] = metrics[\"accuracy\"]\n",
    "    experiments_gru_df.loc['Experiment_' + str(i), 'PRECISON'] = metrics[\"precision\"]\n",
    "    experiments_gru_df.loc['Experiment_' + str(i), 'RECALL'] = metrics[\"recall\"]\n",
    "    experiments_gru_df.loc['Experiment_' + str(i), 'F1 SCORE'] = metrics[\"f1_score\"]\n",
    "    \n",
    "    print('Test Accuracy: %1.4f' % accu + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81594ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_gru_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab0457",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">RNN + GRU</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnngru_model(n_classes,\n",
    "                    activation= 'relu',\n",
    "                    optimizer= 'Adam',\n",
    "                    learning_rate=0.01):\n",
    "    \n",
    "    print('Activation function: ' + activation)\n",
    "    print('Optimizer: ' + optimizer)\n",
    "    print('Learning Rate: ' + str(learning_rate))\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(None,15)))\n",
    "\n",
    "    model.add(\n",
    "        tf.keras.layers.SimpleRNN(225, return_sequences = True, activation = activation)\n",
    "    )\n",
    "\n",
    "\n",
    "    model.add(\n",
    "        tf.keras.layers.GRU(225, activation = activation)\n",
    "    )\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(n_classes))\n",
    "\n",
    "    if optimizer == 'SGD':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    else:\n",
    "        opt = optimiz\n",
    "        print('Optimizer: ' + optimizer)\n",
    "\n",
    "    model.compile(optimizer = opt,\n",
    "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), #set from_ligits=True because our last layer does not apply sigmoid\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18086a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_n_run_rnngru_model(x_train,\n",
    "                          y_train,\n",
    "                          x_test,\n",
    "                          y_test,\n",
    "                          activ= 'relu',\n",
    "                          lear_rt = 0.001,\n",
    "                          optimiz = 'Adam', \n",
    "                          num_epochs = 10,\n",
    "                          verb = False, \n",
    "                          graphing = True):\n",
    "    \n",
    "    print('Number of Epochs: ' + str(num_epochs))\n",
    "    \n",
    "    model = build_rnngru_model(len(label_names), activ, optimiz, lear_rt) \n",
    "    history = model.fit(x_train, \n",
    "                        y_train,\n",
    "                        batch_size = 64,\n",
    "                        epochs = num_epochs, \n",
    "                        validation_split=0.1,\n",
    "                        verbose = verb)\n",
    "    \n",
    "    hist = history.history\n",
    "    if (graphing):\n",
    "        x_arr = np.arange(len(hist['loss'])) + 1\n",
    "        \n",
    "        ## Plot mean CV accuracies for Tree Depth\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        ax.plot(x_arr, hist['loss'], '-o', label='Train loss', \n",
    "             color = 'salmon', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss', \n",
    "                 color = 'firebrick', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Loss vs. Number of Epochs\", weight='bold', color = 'firebrick', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 1, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['salmon','firebrick'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Loss', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(bottom = -0.01)\n",
    "        \n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        ax.plot(x_arr, hist['accuracy'], '-o', label = \"Training Accuracy\", \n",
    "             color = 'royalblue', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_accuracy'], '--<', label = \"Validation Accuracy\", \n",
    "                 color = 'mediumblue', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Accuracy vs. Number of Epochs\", weight='bold', color = 'mediumblue', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 4, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['royalblue','mediumblue'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Accuracy', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(top = 1.01)\n",
    "        \n",
    "        plt.subplots_adjust(wspace=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    test_accuracy = model.evaluate(x_test, y_test, verbose=verb, return_dict=True)['accuracy']\n",
    "    \n",
    "    metrics = compute_model_performance_metrics(model, x_test, y_test)\n",
    "    \n",
    "    train_acc = float(hist['accuracy'][len(hist)-1])\n",
    "    val_acc = float(hist['val_accuracy'][len(hist)-1])\n",
    "    \n",
    "    metrics[\"train_accuracy\"] = format(train_acc, '.4f')\n",
    "    metrics[\"val_accuracy\"] = format(val_acc, '.4f')\n",
    "    \n",
    "    num_params = model.count_params()\n",
    "    \n",
    "    return [test_accuracy, num_params, metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ecc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a Dataframe with all the experiments' information\n",
    "\n",
    "exp_ind = ['Experiment_' + str(i) for i in range(1,7)]\n",
    "activ = ['relu'] * 2 + ['tanh'] * 2 +  ['relu'] * 2\n",
    "lear_rt = ([0.01] + [0.001]) * 3\n",
    "optimiz = ['Adam'] *4 + ['SGD'] * 2\n",
    "\n",
    "experiments_rnngru_df = pd.DataFrame({'activation': activ, \n",
    "                                   'learning rate': lear_rt, \n",
    "                                   'optimizer': optimiz},\n",
    "                             index = exp_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f31817",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range (1,len(experiments_rnngru_df.index)+1):\n",
    "    print('Experiment_' + str(i) + '\\n')\n",
    "    \n",
    "    accu , param, metrics = build_n_run_rnngru_model(X_train_pca_sq, Y_train, X_test_pca_sq, Y_test,\n",
    "                                                  activ= experiments_rnngru_df.loc['Experiment_' + str(i), 'activation'],\n",
    "                                                  lear_rt = experiments_rnngru_df.loc['Experiment_' + str(i), 'learning rate'],\n",
    "                                                  optimiz = experiments_rnngru_df.loc['Experiment_' + str(i), 'optimizer'])\n",
    "\n",
    "    experiments_rnngru_df.loc['Experiment_' + str(i), '# PARAMETERS'] = param\n",
    "    experiments_rnngru_df.loc['Experiment_' + str(i), 'TEST ACCURACY'] = accu\n",
    "    experiments_rnngru_df.loc['Experiment_' + str(i), 'TRAIN ACCURACY'] = metrics[\"train_accuracy\"]\n",
    "    experiments_rnngru_df.loc['Experiment_' + str(i), 'VAL ACCURACY'] = metrics[\"val_accuracy\"]\n",
    "    #experiments_rnngru_df.loc['Experiment_' + str(i), 'ACCURACY'] = metrics[\"accuracy\"]\n",
    "    experiments_rnngru_df.loc['Experiment_' + str(i), 'PRECISON'] = metrics[\"precision\"]\n",
    "    experiments_rnngru_df.loc['Experiment_' + str(i), 'RECALL'] = metrics[\"recall\"]\n",
    "    experiments_rnngru_df.loc['Experiment_' + str(i), 'F1 SCORE'] = metrics[\"f1_score\"]\n",
    "    \n",
    "    print('Test Accuracy: %1.4f' % accu + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_rnngru_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e389f3",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\"> GRU + LSTM</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_grulstm_model(n_classes,\n",
    "                    activation= 'relu',\n",
    "                    optimizer= 'Adam',\n",
    "                    learning_rate=0.01):\n",
    "    \n",
    "    print('Activation function: ' + activation)\n",
    "    print('Optimizer: ' + optimizer)\n",
    "    print('Learning Rate: ' + str(learning_rate))\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(None,15)))\n",
    "\n",
    "    model.add(\n",
    "        tf.keras.layers.GRU(225, return_sequences = True, activation = activation)\n",
    "    )\n",
    "\n",
    "\n",
    "    model.add(\n",
    "        tf.keras.layers.LSTM(225, activation = activation)\n",
    "    )\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(n_classes))\n",
    "\n",
    "    if optimizer == 'SGD':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    else:\n",
    "        opt = optimiz\n",
    "        print('Optimizer: ' + optimizer)\n",
    "\n",
    "    model.compile(optimizer = opt,\n",
    "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), #set from_ligits=True because our last layer does not apply sigmoid\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d95797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_n_run_grulstm_model(x_train,\n",
    "                          y_train,\n",
    "                          x_test,\n",
    "                          y_test,\n",
    "                          activ= 'relu',\n",
    "                          lear_rt = 0.001,\n",
    "                          optimiz = 'Adam', \n",
    "                          num_epochs = 10,\n",
    "                          verb = False, \n",
    "                          graphing = True):\n",
    "    \n",
    "    print('Number of Epochs: ' + str(num_epochs))\n",
    "    \n",
    "    model = build_grulstm_model(len(label_names), activ, optimiz, lear_rt) \n",
    "    history = model.fit(x_train, \n",
    "                        y_train,\n",
    "                        batch_size = 64,\n",
    "                        epochs = num_epochs, \n",
    "                        validation_split=0.1,\n",
    "                        verbose = verb)\n",
    "    \n",
    "    hist = history.history\n",
    "    if (graphing):\n",
    "        x_arr = np.arange(len(hist['loss'])) + 1\n",
    "        \n",
    "        ## Plot mean CV accuracies for Tree Depth\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        ax.plot(x_arr, hist['loss'], '-o', label='Train loss', \n",
    "             color = 'salmon', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss', \n",
    "                 color = 'firebrick', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Loss vs. Number of Epochs\", weight='bold', color = 'firebrick', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 1, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['salmon','firebrick'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Loss', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(bottom = -0.01)\n",
    "        \n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        ax.plot(x_arr, hist['accuracy'], '-o', label = \"Training Accuracy\", \n",
    "             color = 'royalblue', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_accuracy'], '--<', label = \"Validation Accuracy\", \n",
    "                 color = 'mediumblue', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Accuracy vs. Number of Epochs\", weight='bold', color = 'mediumblue', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 4, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['royalblue','mediumblue'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Accuracy', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(top = 1.01)\n",
    "        \n",
    "        plt.subplots_adjust(wspace=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    test_accuracy = model.evaluate(x_test, y_test, verbose=verb, return_dict=True)['accuracy']\n",
    "    \n",
    "    metrics = compute_model_performance_metrics(model, x_test, y_test)\n",
    "    \n",
    "    train_acc = float(hist['accuracy'][len(hist)-1])\n",
    "    val_acc = float(hist['val_accuracy'][len(hist)-1])\n",
    "    \n",
    "    metrics[\"train_accuracy\"] = format(train_acc, '.4f')\n",
    "    metrics[\"val_accuracy\"] = format(val_acc, '.4f')\n",
    "    \n",
    "    num_params = model.count_params()\n",
    "    \n",
    "    return [test_accuracy, num_params, metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01bda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a Dataframe with all the experiments' information\n",
    "\n",
    "exp_ind = ['Experiment_' + str(i) for i in range(1,7)]\n",
    "activ = ['relu'] * 2 + ['tanh'] * 2 +  ['relu'] * 2\n",
    "lear_rt = ([0.01] + [0.001]) * 3\n",
    "optimiz = ['SGD'] * 2 + ['Adam'] *4\n",
    "\n",
    "experiments_grulstm_df = pd.DataFrame({'activation': activ, \n",
    "                                   'learning rate': lear_rt, \n",
    "                                   'optimizer': optimiz},\n",
    "                             index = exp_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4347af40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range (1,len(experiments_grulstm_df.index)+1):\n",
    "    print('Experiment_' + str(i) + '\\n')\n",
    "    \n",
    "    accu , param, metrics = build_n_run_grulstm_model(X_train_pca_sq, Y_train, X_test_pca_sq, Y_test,\n",
    "                                                  activ= experiments_grulstm_df.loc['Experiment_' + str(i), 'activation'],\n",
    "                                                  lear_rt = experiments_grulstm_df.loc['Experiment_' + str(i), 'learning rate'],\n",
    "                                                  optimiz = experiments_grulstm_df.loc['Experiment_' + str(i), 'optimizer'])\n",
    "\n",
    "    experiments_grulstm_df.loc['Experiment_' + str(i), '# PARAMETERS'] = param\n",
    "    experiments_grulstm_df.loc['Experiment_' + str(i), 'TEST ACCURACY'] = accu\n",
    "    experiments_grulstm_df.loc['Experiment_' + str(i), 'TRAIN ACCURACY'] = metrics[\"train_accuracy\"]\n",
    "    experiments_grulstm_df.loc['Experiment_' + str(i), 'VAL ACCURACY'] = metrics[\"val_accuracy\"]\n",
    "    #experiments_grulstm_df.loc['Experiment_' + str(i), 'ACCURACY'] = metrics[\"accuracy\"]\n",
    "    experiments_grulstm_df.loc['Experiment_' + str(i), 'PRECISON'] = metrics[\"precision\"]\n",
    "    experiments_grulstm_df.loc['Experiment_' + str(i), 'RECALL'] = metrics[\"recall\"]\n",
    "    experiments_grulstm_df.loc['Experiment_' + str(i), 'F1 SCORE'] = metrics[\"f1_score\"]\n",
    "    \n",
    "    print('Test Accuracy: %1.4f' % accu + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df0d8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiments_grulstm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc50c911",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\"> Bidirectional LSTM + GRU</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ee1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_blstmgru_model(n_classes,\n",
    "                    activation= 'relu',\n",
    "                    optimizer= 'Adam',\n",
    "                    learning_rate=0.01):\n",
    "    \n",
    "    print('Activation function: ' + activation)\n",
    "    print('Optimizer: ' + optimizer)\n",
    "    print('Learning Rate: ' + str(learning_rate))\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(None,15)))\n",
    "\n",
    "    model.add(\n",
    "        tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.LSTM(225, return_sequences = True, activation = activation)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    model.add(\n",
    "        tf.keras.layers.GRU(225, activation = activation)\n",
    "    )\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(n_classes))\n",
    "\n",
    "    if optimizer == 'SGD':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    else:\n",
    "        opt = optimiz\n",
    "        print('Optimizer: ' + optimizer)\n",
    "\n",
    "    model.compile(optimizer = opt,\n",
    "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), #set from_ligits=True because our last layer does not apply sigmoid\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_n_run_blstmgru_model(x_train,\n",
    "                          y_train,\n",
    "                          x_test,\n",
    "                          y_test,\n",
    "                          activ= 'relu',\n",
    "                          lear_rt = 0.001,\n",
    "                          optimiz = 'Adam', \n",
    "                          num_epochs = 10,\n",
    "                          verb = False, \n",
    "                          graphing = True):\n",
    "    \n",
    "    print('Number of Epochs: ' + str(num_epochs))\n",
    "    \n",
    "    model = build_blstmgru_model(len(label_names), activ, optimiz, lear_rt) \n",
    "    history = model.fit(x_train, \n",
    "                        y_train,\n",
    "                        batch_size = 64,\n",
    "                        epochs = num_epochs, \n",
    "                        validation_split=0.1,\n",
    "                        verbose = verb)\n",
    "    \n",
    "    hist = history.history\n",
    "    if (graphing):\n",
    "        x_arr = np.arange(len(hist['loss'])) + 1\n",
    "        \n",
    "        ## Plot mean CV accuracies for Tree Depth\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        ax.plot(x_arr, hist['loss'], '-o', label='Train loss', \n",
    "             color = 'salmon', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss', \n",
    "                 color = 'firebrick', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Loss vs. Number of Epochs\", weight='bold', color = 'firebrick', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 1, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['salmon','firebrick'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Loss', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(bottom = -0.01)\n",
    "        \n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        ax.plot(x_arr, hist['accuracy'], '-o', label = \"Training Accuracy\", \n",
    "             color = 'royalblue', lw = 1)\n",
    "        ax.plot(x_arr, hist['val_accuracy'], '--<', label = \"Validation Accuracy\", \n",
    "                 color = 'mediumblue', lw = 2)\n",
    "\n",
    "        # Spine formatting\n",
    "        ax.set_facecolor(color='white')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('cornflowerblue')\n",
    "        ax.spines['bottom'].set_color('cornflowerblue')\n",
    "\n",
    "        # Tick formatting\n",
    "        ax.tick_params(axis='y', which='both', length=0, colors = 'gray')\n",
    "        ax.tick_params(axis='x', which='both', colors = 'gray')\n",
    "        ax.set_xticks(range(num_epochs + 1))\n",
    "\n",
    "        # Grid formatting\n",
    "        ax.grid(False)\n",
    "        vals = ax.get_yticks()\n",
    "        for tick in vals:\n",
    "            ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='gainsboro', zorder=1)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Accuracy vs. Number of Epochs\", weight='bold', color = 'mediumblue', \n",
    "                     pad=10, loc='left', size = 18 )\n",
    "\n",
    "        ax.legend(loc = 4, fontsize = 'medium', \n",
    "                  shadow = True,\n",
    "                  edgecolor = 'blue',\n",
    "                  labelcolor = ['royalblue','mediumblue'], \n",
    "                  facecolor = 'ivory')\n",
    "\n",
    "        ax.set_xlabel('Train epochs', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylabel('Accuracy', color = 'gray', weight = 'bold')\n",
    "        ax.set_ylim(top = 1.01)\n",
    "        \n",
    "        plt.subplots_adjust(wspace=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    test_accuracy = model.evaluate(x_test, y_test, verbose=verb, return_dict=True)['accuracy']\n",
    "    \n",
    "    metrics = compute_model_performance_metrics(model, x_test, y_test)\n",
    "    \n",
    "    train_acc = float(hist['accuracy'][len(hist)-1])\n",
    "    val_acc = float(hist['val_accuracy'][len(hist)-1])\n",
    "    \n",
    "    metrics[\"train_accuracy\"] = format(train_acc, '.4f')\n",
    "    metrics[\"val_accuracy\"] = format(val_acc, '.4f')\n",
    "    \n",
    "    num_params = model.count_params()\n",
    "    \n",
    "    return [test_accuracy, num_params, metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a Dataframe with all the experiments' information\n",
    "\n",
    "exp_ind = ['Experiment_' + str(i) for i in range(1,7)]\n",
    "activ = ['relu'] * 2 + ['tanh'] * 2 +  ['relu'] * 2\n",
    "lear_rt = ([0.01] + [0.001]) * 3\n",
    "optimiz = ['SGD'] * 2 + ['Adam'] *4\n",
    "\n",
    "experiments_blstmgru_df = pd.DataFrame({'activation': activ, \n",
    "                                   'learning rate': lear_rt, \n",
    "                                   'optimizer': optimiz},\n",
    "                             index = exp_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b7acb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range (1,len(experiments_blstmgru_df.index)+1):\n",
    "    print('Experiment_' + str(i) + '\\n')\n",
    "    \n",
    "    accu , param, metrics = build_n_run_blstmgru_model(X_train_pca_sq, Y_train, X_test_pca_sq, Y_test,\n",
    "                                                  activ= experiments_blstmgru_df.loc['Experiment_' + str(i), 'activation'],\n",
    "                                                  lear_rt = experiments_blstmgru_df.loc['Experiment_' + str(i), 'learning rate'],\n",
    "                                                  optimiz = experiments_blstmgru_df.loc['Experiment_' + str(i), 'optimizer'])\n",
    "\n",
    "    experiments_blstmgru_df.loc['Experiment_' + str(i), '# PARAMETERS'] = param\n",
    "    experiments_blstmgru_df.loc['Experiment_' + str(i), 'TEST ACCURACY'] = accu\n",
    "    experiments_blstmgru_df.loc['Experiment_' + str(i), 'TRAIN ACCURACY'] = metrics[\"train_accuracy\"]\n",
    "    experiments_blstmgru_df.loc['Experiment_' + str(i), 'VAL ACCURACY'] = metrics[\"val_accuracy\"]\n",
    "    #experiments_blstmgru_df.loc['Experiment_' + str(i), 'ACCURACY'] = metrics[\"accuracy\"]\n",
    "    experiments_blstmgru_df.loc['Experiment_' + str(i), 'PRECISON'] = metrics[\"precision\"]\n",
    "    experiments_blstmgru_df.loc['Experiment_' + str(i), 'RECALL'] = metrics[\"recall\"]\n",
    "    experiments_blstmgru_df.loc['Experiment_' + str(i), 'F1 SCORE'] = metrics[\"f1_score\"]\n",
    "    \n",
    "    print('Test Accuracy: %1.4f' % accu + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faefc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_blstmgru_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffecf00",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px;background-color: cornflowerblue; color:white;font-size:28px;\">Support Vector Machine (SVM) </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692069a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','poly']}\n",
    "\n",
    "svc=svm.SVC(\n",
    "        probability=True \n",
    "        #,verbose=True enable for debug\n",
    "        )\n",
    "\n",
    "model=RandomizedSearchCV(\n",
    "        svc, \n",
    "        param_grid, \n",
    "        cv=3, \n",
    "        n_jobs=-1 # use all cores\n",
    "        #,verbose=4 enable for debug\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e3f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "model.fit(X_train_pca,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13080b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print results\n",
    "\n",
    "Y_pred = model.predict(X_test_pca)\n",
    "\n",
    "accuracy = accuracy_score(Y_test,Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='macro')\n",
    "recall = recall_score(Y_test, Y_pred, average='macro')\n",
    "f1 = f1_score(Y_test, Y_pred, average='macro')\n",
    "\n",
    "print('accuracy: ', accuracy)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('F1 score: ', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e04aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.best_params_ contains the best parameters obtained from GridSearchCV\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f22935",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
